# âœ… Streamlit ê¸°ë°˜ ìµœì¢… í†µí•© ë²„ì „ (UI + ë¡œì§ í†µí•©)

import streamlit as st

# âœ… ìŠ¤íƒ€ì¼ ë° ë°˜ì‘í˜• CSS ì¶”ê°€
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
        
        html, body, .stApp {
            background-color: #000000 !important;
            color: #FFFFFF !important;
            font-family: 'Noto Sans KR', sans-serif !important;
        }

        /* âœ… ì…ë ¥ì°½ ìŠ¤íƒ€ì¼ */
        textarea {
            background-color: #f0f0f0 !important;
            color: #000000 !important;
            border-radius: 6px !important;
            padding: 10px !important;
            border: 1px solid #666 !important;
        }

        /* âœ… ë¬¼ì–´ë³´ê¸° ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
        button[title="ë¬¼ì–´ë³´ê¸°"] {
            background-color: #000000 !important;
            color: white !important;
            border: 1px solid #ccc !important;
            border-radius: 6px !important;
        }

        /* âœ… ì‚¬ìš©ì/ì±—ë´‡ ë§í’ì„  */
        .user-msg-box {
            text-align: right;
        }
        .chatbot-msg-box {
            text-align: left;
        }
        .user-msg {
            display: inline-block; 
            text-align: left; 
            background-color: #FFEB3B; 
            color: #000000; 
            padding: 10px 14px; 
            border-radius: 12px 0px 12px 12px; 
            margin: 0 0 30px 0; 
            max-width: 66%;
        }
        .chatbot-msg {
            display: inline-block; 
            text-align: left; 
            background-color: #FFFFFF; 
            color: #000000; 
            padding: 10px 14px; 
            border-radius: 12px 0px 12px 12px; 
            margin: 0 0 30px 0; 
            max-width: 66%;
        }

        @media screen and (max-width: 768px) {
            .input-row {
                flex-direction: column;
                align-items: stretch;
            }
        }
    </style>
    <script>
        // ë²„íŠ¼ì— title ê°•ì œ ì§€ì •
        window.addEventListener('load', function () {
            const buttons = parent.document.querySelectorAll('button');
            for (const btn of buttons) {
                if (btn.innerText === "ë¬¼ì–´ë³´ê¸°") {
                    btn.title = "ë¬¼ì–´ë³´ê¸°";
                }
            }
        });
    </script>
""", unsafe_allow_html=True)


import faiss
import pickle
import numpy as np
import random
import itertools
from collections import deque
from openai import OpenAI


# âœ… ìƒíƒœ ì´ˆê¸°í™”
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ê´€ê´‘ê¸°ì—… ìƒë‹´ ì „ë¬¸ê°€ í˜¸ì¢…ì´ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ ì•„ë˜ ì§€ì¹¨ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:\n\n- ë‹µë³€ì€ ì¹œì ˆí•œ ìƒë‹´ì‚¬ ë§íˆ¬ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n- ì‚¬ìš©ì ì§ˆë¬¸ì— 'ì¶”ì²œ', 'ì œì‹œ', 'ì°¾ì•„', 'ê²€ìƒ‰í•´' ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ë©´ ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ê° í•­ëª©ì— ê¸°ì—…ëª…, ì„œë¹„ìŠ¤ëª…, ê¸°ì—…ID, ì„œë¹„ìŠ¤ìœ í˜•, ê¸ˆì•¡, ê¸°í•œ ì •ë³´ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.\n- ëª©ë¡ì€ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”:\n  1. \"ì„œë¹„ìŠ¤ëª…\"\n     - \"ê¸°ì—…ëª…\" (ê¸°ì—…ID: XXXX)\n     - ìœ í˜•: ...\n     - ê¸ˆì•¡: ...\n     - ê¸°í•œ: ...\n     - ìš”ì•½: ...\n- íŠ¹ìˆ˜ë¬¸ì(**, ## ë“±)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , ë¶ˆë¦¿ì€ ëŒ€ì‹œ(-)ë¡œë§Œ í†µì¼í•´ ì£¼ì„¸ìš”. í•­ëª© ê°„ ê°œí–‰ ì—†ì´ ì´ì–´ì„œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n- ê¸°ì—…ëª…/ì„œë¹„ìŠ¤ëª…ì´ ë‚˜ì˜¤ë©´ ë°˜ë“œì‹œ ì´ìœ ë„ í•¨ê»˜ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n- ê¸°ì—…IDëŠ” ë°˜ë“œì‹œ ê´„í˜¸ ì•ˆì— í‘œê¸°í•´ ì£¼ì„¸ìš”. ì˜ˆ: \"ì œì´ì–´ìŠ¤\" (ê¸°ì—…ID: 12345)"}
    ]
if "all_results" not in st.session_state:
    st.session_state.all_results = deque(maxlen=5)
if "excluded_company_ids" not in st.session_state:
    st.session_state.excluded_company_ids = set()
if "last_results" not in st.session_state:
    st.session_state.last_results = []
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []

# âœ… GPT & FAISS ì¤€ë¹„
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
index = faiss.read_index("service_index.faiss")
with open("service_metadata.pkl", "rb") as f:
    metadata = pickle.load(f)

xb = index.reconstruct_n(0, index.ntotal)
xb = xb / np.linalg.norm(xb, axis=1, keepdims=True)
d = xb.shape[1]
index_cosine = faiss.IndexFlatIP(d)
index_cosine.add(xb)

# âœ… í•¨ìˆ˜ ì •ì˜
def get_embedding(text, model="text-embedding-3-small"):
    response = client.embeddings.create(input=[text], model=model)
    return response.data[0].embedding

def ask_gpt(messages):
    response = client.chat.completions.create(model="gpt-4o", messages=messages)
    return response.choices[0].message.content

def is_best_recommendation_query(query):
    return any(k in query for k in ["ì¶”ì²œ", "ê°•ì¶”", "ì œì‹œ", "ì°¾ì•„", "ê²€ìƒ‰í•´"])

def is_relevant_question(query, threshold=0.3):
    query_vec = get_embedding(query)
    query_vec = np.array(query_vec).astype('float32').reshape(1, -1)
    query_vec /= np.linalg.norm(query_vec, axis=1, keepdims=True)
    D, _ = index_cosine.search(query_vec, 1)
    return D[0][0] >= threshold

def recommend_services(query, top_k=5, exclude_company_ids=None):
    query_vec = get_embedding(query)
    query_vec = np.array(query_vec).astype('float32').reshape(1, -1)
    query_vec /= np.linalg.norm(query_vec, axis=1, keepdims=True)
    D, indices = index_cosine.search(query_vec, 100)
    
    candidate_services = {}
    for score, idx in zip(D[0], indices[0]):
        service = metadata[idx]
        cid = service["ê¸°ì—…ID"]
        if exclude_company_ids and cid in exclude_company_ids:
            continue
        key = (cid, service.get("ì„œë¹„ìŠ¤ìœ í˜•"))
        candidate_services.setdefault(key, []).append((score, service))

    best_services = [random.choice(v) for v in candidate_services.values()]
    best_services.sort(key=lambda x: x[0], reverse=True)
    return [s for _, s in best_services[:top_k]]

def make_context(results):
    return "\n".join([
        f"{i+1}. \"{s['ì„œë¹„ìŠ¤ëª…']}\" (ì œê³µê¸°ì—…: \"{s['ê¸°ì—…ëª…']}\", ê¸°ì—…ID: {s['ê¸°ì—…ID']})\n"
        f"- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½', '')}\n"
        f"- ê¸ˆì•¡: {s.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', 'ì •ë³´ ì—†ìŒ')} / ê¸°í•œ: {s.get('ì„œë¹„ìŠ¤ê¸°í•œ', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ë²•ì¸ì—¬ë¶€: {s.get('ê¸°ì—…ì˜ ë²•ì¸ì—¬ë¶€', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ìœ„ì¹˜: {s.get('ê¸°ì—… ìœ„ì¹˜', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- í•µì‹¬ì—­ëŸ‰: {s.get('ê¸°ì—… í•µì‹¬ì—­ëŸ‰', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- 3ê°œë…„ í‰ê·  ë§¤ì¶œ: {s.get('ê¸°ì—… 3ê°œë…„ í‰ê·  ë§¤ì¶œ', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- í•´ë‹¹ë¶„ì•¼ì—…ë ¥: {s.get('ê¸°ì—… í•´ë‹¹ë¶„ì•¼ì—…ë ¥', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ì£¼ìš”ì‚¬ì—…ë‚´ìš©: {s.get('ê¸°ì—… ì£¼ìš”ì‚¬ì—…ë‚´ìš©', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ì¸ë ¥í˜„í™©: {s.get('ê¸°ì—… ì¸ë ¥í˜„í™©', 'ì •ë³´ ì—†ìŒ')}"
        for i, s in enumerate(results)
    ])

def make_summary_context(summary_memory):
    seen = set()
    deduped = []
    for result_list in reversed(summary_memory):
        for item in result_list:
            key = (item['ì„œë¹„ìŠ¤ëª…'], item['ê¸°ì—…ëª…'], item.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', ''))
            if key not in seen:
                seen.add(key)
                deduped.insert(0, item)
    return "\n".join([
        f"{i+1}. {s['ì„œë¹„ìŠ¤ëª…']} ({s['ê¸°ì—…ëª…']})\n- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•')}\n- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½')}"
        for i, s in enumerate(deduped)
    ])

def make_prompt(query, context, is_best):
    extra = f"ì§€ê¸ˆê¹Œì§€ ì¶”ì²œí•œ ì„œë¹„ìŠ¤ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n{make_summary_context(st.session_state.all_results)}\n\nì´ì „ì— ì¶”ì²œëœ ê¸°ì—…ë„ í¬í•¨í•´ì„œ ì¡°ê±´ì— ê°€ì¥ ë¶€í•©í•˜ëŠ” ìµœê³ ì˜ ì¡°í•©ì„ ì œì‹œí•´ì£¼ì„¸ìš”." if is_best else ""
    return f"""
ë‹¹ì‹ ì€ ê´€ê´‘ìˆ˜í˜œê¸°ì—…ì—ê²Œ ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” AI ìƒë‹´ì‚¬ í˜¸ì¢…ì´ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
"{query}"

ê·¸ë¦¬ê³  ê´€ë ¨ëœ ì„œë¹„ìŠ¤ ëª©ë¡ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:
{context}

ğŸ“Œ {extra}
"""

# âœ… UI ì¶œë ¥ ì˜ì—­
st.markdown("""
    <h1 style='text-align: center;'>í˜ì‹ ë°”ìš°ì²˜ ì„œë¹„ìŠ¤ íŒŒì¸ë”</h1>
    <p style='text-align: center; font-size:14px;'>ğŸ¤– í˜¸ì¢…ì´ì—ê²Œ ê´€ê´‘ê¸°ì—… ì„œë¹„ìŠ¤ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”.</p>
""", unsafe_allow_html=True)

for msg in st.session_state.chat_messages:
    if msg["role"] == "user":
        st.markdown(f"""
        <div class="user-msg-box">
            <div class="user-msg">
                {msg["content"].replace(chr(10), "<br>")}
            </div>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chatbot-msg-box">
            <div class="chatbot-msg"> 
                {msg["content"].replace(chr(10), "<br>")}
            </div>
        </div>
        """, unsafe_allow_html=True)

with st.form("chat_form", clear_on_submit=True):
    st.markdown("<div class='input-row'>", unsafe_allow_html=True)
    user_input = st.text_area("", height=100, label_visibility="collapsed")
    submitted = st.form_submit_button("ë¬¼ì–´ë³´ê¸°")
    st.markdown("</div>", unsafe_allow_html=True)

st.markdown("""
    <div style='font-size: 14px; margin-top: 4px; color: #CCCCCC; text-align: left;'>
        â„¹ï¸ ì‚¬ìš©ë²• ì•ˆë‚´:<br>
        â€¢&nbsp;<b>"ìì„¸íˆ ê¸°ì—…ëª…"</b>ì„ ì…ë ¥í•˜ë©´ í•´ë‹¹ ê¸°ì—…ì˜ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.<br>
        â€¢&nbsp;<b>"ê°•ë ¥ ì¶”ì²œ"</b> ì„ í¬í•¨í•˜ì—¬ ì§ˆë¬¸í•˜ë©´ ì•ì„œ ì œì‹œëœ ë‚´ìš©ë“¤ì„ í¬í•¨í•œ ì „ì²´ ì¶”ì²œì„ ë°›ì•„ë³¼ ìˆ˜ ìˆì–´ìš”.<br>
        â€¢&nbsp;ë³µí•©ì ì¸ ì¡°ê±´ë“¤ì„ ì´ìš©í•œ ì§ˆë¬¸ìœ¼ë¡œ í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•´ ë³´ì„¸ìš”.<br>
        ì˜ˆë¥¼ë“¤ì–´ "ìš°ë¦¬ íšŒì‚¬ëŠ” ì™¸êµ­ì¸ì—ê²Œ êµ­ë‚´ ìœ ëª… ê´€ê´‘ì§€ì—­ì„ ì†Œê°œí•˜ê³  ìˆ™ë°•ì„ ì—°ê²°í•´ì£¼ëŠ” ì„œë¹„ìŠ¤ë¥¼ í•˜ê³  ìˆì–´. íšŒì‚¬ í™ˆí˜ì´ì§€ë¥¼ ë””ìì¸ ì¤‘ì‹¬ìœ¼ë¡œ ê°œí¸í•˜ê³  ì‹¶ê³ , ì°¸ ë‹¤êµ­ì–´ëŠ” í•„ìˆ˜ê³ , ìˆ™ë°•ì§€ë¥¼ ì˜ˆì•½í•˜ê³  ê²°ì œí•˜ëŠ” ì‡¼í•‘ëª° ê¸°ëŠ¥ì´ ë°˜ë“œì‹œ í•„ìš”í•´. ë˜í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ìœ¼ë¡œ í™ë³´ë„ ì˜ í•˜ëŠ” ê²ƒë„ í•„ìˆ˜ê³ . ì´ëŸ°ê±¸ ë§Œì¡±ì‹œí‚¬ ìˆ˜ ìˆëŠ” ì¡°í•©ì„ ë§Œë“¤ì–´ì¤˜. ë‹¨, ì˜ˆì‚°ì€ í•©ì³ì„œ 5,000ë§Œì›ê¹Œì§€ì´ê³ , ê¸°ê°„ì€ 3.5ê°œì›”ì•ˆì—ëŠ” ë§ˆì³ì•¼ í•´. ë§ì€ ì†Œí†µì„ ìœ„í•´ ê°€ê¸‰ì  ìˆ˜ë„ê¶Œ ì§€ì—­ì— ìˆëŠ” íšŒì‚¬ì˜€ìœ¼ë©´ ì¢‹ê² ê³ , ë§¤ì¶œë„ 30ì–µ ì´ìƒë˜ë©° ì¸ì›ë„ ë§ì•„ì„œ ì•ˆì •ì ì¸ ì§€ì›ë„ ë°›ì•˜ìœ¼ë©´ í•˜ê³ . ì´ëŸ° íšŒì‚¬ë“¤ë¡œ ì°¾ì•„ë´ì¤˜. ë˜ ì–´ë–»ê²Œ ì´ë“¤ì„ ì¡°í•©í•˜ë©´ ë˜ëŠ”ì§€, ì™œ ì¶”ì²œí–ˆëŠ”ì§€ë„ ìƒì„¸íˆ ì•Œë ¤ì¤˜."
    </div>
""", unsafe_allow_html=True)   

if submitted and user_input.strip():
    st.session_state.conversation_history.append({"role": "user", "content": user_input})
    st.session_state.chat_messages.append({"role": "user", "content": user_input})

    if user_input.startswith("ìì„¸íˆ"):
        keyword = user_input.replace("ìì„¸íˆ", "").strip()
        all_results = list(itertools.chain.from_iterable(st.session_state.all_results))
        matches = [s for s in all_results if keyword in s["ê¸°ì—…ëª…"]]
        if not matches:
            reply = "â— í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ê¸°ì—…ëª…ì´ ì—†ìŠµë‹ˆë‹¤."
        elif len(matches) > 1:
            reply = "â— ì—¬ëŸ¬ ê°œì˜ ê¸°ì—…ëª…ì´ ì¼ì¹˜í•©ë‹ˆë‹¤:<br>" + "<br>".join(f"- {s['ê¸°ì—…ëª…']}" for s in matches)
        else:
            s = matches[0]
            details = [f"â€¢ {k}: {v}" for k, v in s.items()]
            reply = "<br>".join(details)
        st.session_state.chat_messages.append({"role": "assistant", "content": reply})
        st.rerun()
    else:
        if not is_relevant_question(user_input):
            msg = "â— ê´€ê´‘ê¸°ì—…ì´ë‚˜ ì„œë¹„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”."
            st.session_state.chat_messages.append({"role": "assistant", "content": msg})
            st.rerun()

        best_mode = is_best_recommendation_query(user_input)
        exclude = None if best_mode else st.session_state.excluded_company_ids
        results = recommend_services(user_input, exclude_company_ids=exclude)

        if not best_mode:
            for s in results:
                st.session_state.excluded_company_ids.add(s["ê¸°ì—…ID"])

        st.session_state.last_results = results
        st.session_state.all_results.append(results)

        context = make_context(results)
        prompt = make_prompt(user_input, context, is_best=best_mode)
        st.session_state.conversation_history.append({"role": "user", "content": prompt})

        gpt_reply = ask_gpt(st.session_state.conversation_history)
        st.session_state.conversation_history.append({"role": "assistant", "content": gpt_reply})
        st.session_state.chat_messages.append({"role": "assistant", "content": gpt_reply})

        st.rerun()
