
import streamlit as st
import streamlit.components.v1 as components
import faiss
import pickle
import numpy as np
import random
from collections import deque
import itertools
from datetime import datetime
from zoneinfo import ZoneInfo  # Python 3.9 ì´ìƒ
from sentence_transformers import SentenceTransformer

# âœ… ì§„ì… ì•”í˜¸ ì…ë ¥ ë¡œì§ (4ìë¦¬ ìˆ«ì ì˜ˆ: 7299)
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.markdown("## ğŸ” ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤")
    password_input = st.text_input("4ìë¦¬ ìˆ«ì ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
    if password_input and password_input.strip() == "7299":
        st.session_state.authenticated = True
        st.rerun()
    elif password_input:
        st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
    st.stop()

# âœ… ì¸ì¦ ì´í›„ ì‹¤í–‰
st.set_page_config(layout="wide")

from openai import OpenAI
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… ìŠ¤íƒ€ì¼ ë° ë°˜ì‘í˜• CSS ì¶”ê°€
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
        
        html, body, .stApp {
            background-color: #FFFFFF !important;
            color: #0c0c0c !important;
            font-family: 'Noto Sans KR', sans-serif !important;
        }

        /* âœ… ì…ë ¥ì°½ */
        .stTextArea textarea {
            background-color: #f0f0f0 !important;
            color: #0c0c0c !important;
            border-radius: 6px !important;
            padding: 10px !important;
            border: 1px solid #DDDDDD !important;
        }

        /* âœ… ë²„íŠ¼ */
        .stButton > button {
            background-color: #0c0c0c !important;
            color: #FFFFFF !important;
            padding: 10px 16px !important;
            border-radius: 6px !important;
            border: 2px solid #FFFFFF !important;
        }

        /* âœ… ì‚¬ìš©ì/ì±—ë´‡ ë§í’ì„  */
        .user-msg-box {
            text-align: right !important;
        }
        .user-msg {
            display: inline-block !important;
            text-align: left !important; 
            background-color: #FFEB3B !important; 
            color: #0c0c0c !important;
            padding: 10px 14px !important; 
            border-radius: 12px 0px 12px 12px; 
            margin: 0 0 30px 0 !important; 
            max-width: 66% !important;
            word-wrap: break-word !important;
            overflow-wrap: break-word !important;
            word-break: break-all !important;
        }
        .user-msg-time {
            text-align: left !important;
            font-size: 11px;
            color: #666;
            margin-top: 2px;
            width: 100%;
        }    
        .chatbot-msg-box {
            text-align: left !important;
        }
        .chatbot-msg {
            display: inline-block !important; 
            text-align: left !important !important; 
            background-color: #bacee0 !important; 
            color: #0c0c0c !important !important;
            padding: 10px 14px !important; 
            border-radius: 12px 0px 12px 12px !important; 
            margin: 0 0 30px 0 !important; 
            max-width: 66% !important;
            word-wrap: break-word !important;
            overflow-wrap: break-word !important;
            word-break: break-all !important;
        }
        .chatbot-msg-time {
            text-align: right !important; 
            font-size: 11px;
            color: #666;
            margin-top: 2px;
            width: 100%;
        }   
        /* âœ… ê¸°íƒ€ */
        .responsive-title {
            font-size: clamp(40px, 5vw, 60px) !important;
            font-weight: 700 !important;
            color: #0c0c0c !important;  
            text-align: center !important;
            white-space: nowrap !important;
            overflow: hidden !important;
            width: 100% !important;
            padding-bottom: 2px !important;
            margin-top: -52px !important;
        }
        .responsive-subtitle {
            font-size: clamp(14px, 5vw, 12px) !important;
            color: #0c0c0c !important;  
            text-align: center !important;
            white-space: nowrap !important;
            overflow: hidden !important;
            width: 100% !important;
            padding-bottom: 2px !important;
        }
        .user-guide {
            font-size: 14px !important;
            margin-top: 4px !important; 
            color: #0c0c0c !important; 
            text-align: left !important;
            line-height: 1.4 !important;
        }
        
        /* ë§í¬ ìŠ¤íƒ€ì¼ */
        .link-button {
            display: inline-block;
            background-color: #f8f9fa;
            color: #0366d6;
            padding: 5px 10px;
            border-radius: 4px;
            margin: 5px 0;
            text-decoration: none;
            border: 1px solid #ddd;
            white-space: normal;
            word-break: break-all;
            max-width: 100%;
        }
        
        @media screen and (max-width: 768px) {
            .input-row {
                flex-direction: column !important;
                align-items: stretch !important;
            }
            .user-msg, .chatbot-msg {
                font-size: 12px !important;
                line-height: 1.3 !important;
            }
            .user-msg-time, chatbot-msg-time {
                font-size: 9x;
            }   
            .user-guide {
                font-size: 11px !important;
                line-height: 1.3 !important;
            }
        }
        
        .main .block-container {
            padding-top: 1rem !important;
        }
    </style>
""", unsafe_allow_html=True)

# âœ… ì„¤ì • ë³€ìˆ˜ (13_service_recommender.pyì™€ ì¼ì¹˜í•˜ë„ë¡ ìœ ì§€)
USE_OPENAI_EMBEDDING = True  # ğŸ” ì—¬ê¸°ì„œ ìŠ¤ìœ„ì¹­ ê°€ëŠ¥ (True: OpenAI, False: ë¡œì»¬ ëª¨ë¸)
Q_SIMILARITY_THRESHOLD = 0.30
A_SIMILARITY_THRESHOLD = 0.45
MAX_HISTORY_LEN = 5  # ì§ˆë¬¸ê³¼ ë‹µë³€ íˆìŠ¤ë¡œë¦¬ ì €ì¥ ì»¨í…ìŠ¤íŠ¸ ê°œìˆ˜

# âœ… ì„¸ì…˜ ìƒíƒœì— ë””ë²„ê·¸ ëª¨ë“œ ë³€ìˆ˜ ì¶”ê°€
if "debug_mode" not in st.session_state:
    st.session_state.debug_mode = False

# # ì‚¬ì´ë“œë°”ì— ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€ ì¶”ê°€
# with st.sidebar:
#     st.title("ê°œë°œì ì„¤ì •")
#     debug_toggle = st.checkbox("ë””ë²„ê·¸ ëª¨ë“œ", value=st.session_state.debug_mode)
#     if debug_toggle != st.session_state.debug_mode:
#         st.session_state.debug_mode = debug_toggle
#         st.rerun()

# ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ í•¨ìˆ˜
def debug_info(message, level="info", pin=False):
    """ë””ë²„ê·¸ ëª¨ë“œì¼ ë•Œë§Œ í‘œì‹œ + í•€ ë©”ì‹œì§€ëŠ” ì…ë ¥ì°½ ìœ„ì— ê³ ì •"""
    if st.session_state.debug_mode:
        if pin:
            st.session_state.debug_pinned_message = message  # âœ… ê³ ì • ë©”ì‹œì§€ë¡œ ë“±ë¡
        if level == "info":
            st.info(message)
        elif level == "warning":
            st.warning(message)
        elif level == "error":
            st.error(message)
        elif level == "success":
            st.success(message)
        else:
            st.write(message)


# âœ… ë¡œì»¬ ëª¨ë¸ ì´ˆê¸°í™” (í•„ìš” ì‹œ)
if not USE_OPENAI_EMBEDDING:
    local_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

# âœ… KST ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
def get_kst_time():
    return datetime.now(ZoneInfo("Asia/Seoul")).strftime("%p %I:%M")

# âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = deque(maxlen=MAX_HISTORY_LEN + 1)  # system ë©”ì‹œì§€ í¬í•¨ì„ ìœ„í•´ +1
    st.session_state.conversation_history.append({
        "role": "system",
        "content": "ë‹¹ì‹ ì€ ê´€ê´‘ê¸°ì—… ìƒë‹´ ì „ë¬¸ê°€ í˜¸ì¢…ì´ì…ë‹ˆë‹¤. "
                "ëª¨ë“  ë‹µë³€ì€ ì•„ë˜ ì§€ì¹¨ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:\n\n"
                "- ë‹µë³€ì€ ì¹œì ˆí•œ ìƒë‹´ì‚¬ ë§íˆ¬ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
                "- ì‚¬ìš©ì ì§ˆë¬¸ì— \"ì¶”ì²œ\", \"ì œì‹œ\", \"ì°¾ì•„\", \"ê²€ìƒ‰í•´\" ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ë©´ ë°˜ë“œì‹œ ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
                " ë§Œì¼ ê·¸ëŸ° ê²½ìš°ê°€ ì•„ë‹ˆë¼ë©´, ì„œìˆ ì‹ì¼ ê²½ìš° ìì—°ìŠ¤ëŸ½ê³  í¬ê´„ì ì¸ ì„¤ëª…ìœ¼ë¡œ êµ¬ì„±í•´ ì£¼ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ìŠ¤íƒ€ì¼(**, ## ë“±)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
                "- ëª©ë¡ìœ¼ë¡œ ì¶œë ¥í•  ê²½ìš° ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n"
                "\n"
                "  1. \"ì„œë¹„ìŠ¤ëª…\"\n"
                "     - \"ê¸°ì—…ëª…\" (ê¸°ì—…ID: XXXX)\n"
                "     - ìœ í˜•: ...\n"
                "     - ê¸ˆì•¡: ...\n"
                "     - ê¸°í•œ: ...\n"
                "     - ìš”ì•½: ...\n"
                "     -...\n"
                "\n"
                "- ë°˜ë“œì‹œ ìœ„ í˜•ì‹ì„ ì§€ì¼œì£¼ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ìŠ¤íƒ€ì¼(**, ## ë“±)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
                "- ë¶ˆë¦¿ì€ í•­ìƒ ëŒ€ì‹œ(-)ë§Œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.\n"
                "- í•­ëª© ê°„ ê°œí–‰ì„ ë„£ì§€ ë§ˆì„¸ìš”.\n"
                "- ê¸°ì—…ëª…/ì„œë¹„ìŠ¤ëª…ì´ ì–¸ê¸‰ë˜ë©´ ë°˜ë“œì‹œ ì´ìœ ë„ í•¨ê»˜ ì œì‹œí•´ ì£¼ì„¸ìš”.\n"
                "- ê¸°ì—…IDëŠ” ë°˜ë“œì‹œ ê´„í˜¸ ì•ˆì— í‘œê¸°í•´ ì£¼ì„¸ìš”. ì˜ˆ: \"ì œì´ì–´ìŠ¤\" (ê¸°ì—…ID: 12345)"
    })
if "all_results" not in st.session_state:
    st.session_state.all_results = deque(maxlen=MAX_HISTORY_LEN)
if "excluded_keys" not in st.session_state:
    st.session_state.excluded_keys = set()
if "last_results" not in st.session_state:
    st.session_state.last_results = []
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []
if "embedding_cache" not in st.session_state:
    st.session_state.embedding_cache = {}
if "followup_cache" not in st.session_state:
    st.session_state.followup_cache = {}
if "user_query_history" not in st.session_state:
    st.session_state.user_query_history = []
if "embedding_query_text" not in st.session_state:
    st.session_state.embedding_query_text = None


# âœ… ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def normalize(vecs):
    norms = np.linalg.norm(vecs, axis=1, keepdims=True)
    return vecs / norms

# âœ… FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ
@st.cache_resource
def load_index_and_metadata():
    index = faiss.read_index("service_index.faiss")
    with open("service_metadata.pkl", "rb") as f:
        metadata = pickle.load(f)
    
    # ì €ì¥ëœ ì„ë² ë”© ë²¡í„°ë¥¼ ì¬êµ¬ì„±í•˜ê³  ì •ê·œí™”
    xb = index.reconstruct_n(0, index.ntotal)
    xb = normalize(xb)
    d = xb.shape[1]
    index_cosine = faiss.IndexFlatIP(d)
    index_cosine.add(xb)
    
    return index, metadata, index_cosine

# ê¸°ì—… IDë¥¼ í‚¤ë¡œ, ê¸°ì—…ëª…ì„ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
@st.cache_resource
def create_company_lookup():
    company_dict = {}
    for item in metadata:
        if "ê¸°ì—…ID" in item and "ê¸°ì—…ëª…" in item:
            company_dict[str(item["ê¸°ì—…ID"])] = item["ê¸°ì—…ëª…"]
    return company_dict

# âš ï¸ ì´ í˜¸ì¶œì€ í•¨ìˆ˜ ì •ì˜ í›„ì— ë°°ì¹˜
index, metadata, index_cosine = load_index_and_metadata()
company_lookup = create_company_lookup()


def get_embedding(text, model="text-embedding-3-small"):
    if text in st.session_state.embedding_cache:
        return st.session_state.embedding_cache[text]

    if USE_OPENAI_EMBEDDING:
        response = client.embeddings.create(input=[text], model=model)
        embedding = response.data[0].embedding  # ìˆ˜ì •ëœ ë¶€ë¶„: ë”•ì…”ë„ˆë¦¬ ì ‘ê·¼ì´ ì•„ë‹Œ ê°ì²´ ì†ì„± ì ‘ê·¼
    else:
        embedding = local_model.encode([text])[0].tolist()

    st.session_state.embedding_cache[text] = embedding
    return embedding

def is_followup_question(prev, current):
    key = (prev.strip(), current.strip())  # ì „ì²˜ë¦¬ëœ ì§ˆë¬¸ ìŒì„ ìºì‹œ í‚¤ë¡œ ì‚¬ìš©

    if key in st.session_state.followup_cache:
        return st.session_state.followup_cache[key]

    messages = [
        {"role": "system", "content": "ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì´ ì´ì „ ì§ˆë¬¸ì— ëŒ€í•œ í›„ì† ì§ˆë¬¸ì¸ì§€ ì•„ë‹Œì§€ë¥¼ íŒë‹¨í•´ ì£¼ì„¸ìš”. í›„ì†ì´ë©´ YES, ì•„ë‹ˆë©´ NOë¡œë§Œ ë‹µí•´ ì£¼ì„¸ìš”."},
        {"role": "user", "content": f"ì´ì „ ì§ˆë¬¸: {prev}\ní˜„ì¬ ì§ˆë¬¸: {current}"}
    ]
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )
        answer = response.choices[0].message.content.strip().lower() 
        result = "yes" in answer  # 'yes' í¬í•¨ ì—¬ë¶€ë¡œ íŒë‹¨
        st.session_state.followup_cache[key] = result  # âœ… ìºì‹œ ì €ì¥
        return result
    except Exception as e:
        return True  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ì€ í›„ì† ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼

def is_best_recommendation_query(query):
    keywords = ["ê°•ë ¥ ì¶”ì²œ", "ê°•ì¶”"]
    return any(k in query for k in keywords)

def is_relevant_question(query, threshold=Q_SIMILARITY_THRESHOLD):
    query_vec = get_embedding(query)
    query_vec = np.array(query_vec).astype('float32').reshape(1, -1)
    query_vec = normalize(query_vec)
    D, _ = index_cosine.search(query_vec, 1)
    max_similarity = D[0][0]
    return max_similarity >= threshold

def is_related_results_enough(ranked_results, threshold=A_SIMILARITY_THRESHOLD, top_n=MAX_HISTORY_LEN):
    """
    ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ê²°ê³¼ ì¤‘ ìƒìœ„ Nê°œì˜ í‰ê·  ìœ ì‚¬ë„ê°€ threshold ì´ìƒì¸ì§€ í™•ì¸.
    ê´€ë ¨ë„ê°€ ë‚®ìœ¼ë©´ False ë°˜í™˜ â†’ GPT í˜¸ì¶œ ë°©ì§€ ê°€ëŠ¥.
    """
    if not ranked_results or len(ranked_results) < top_n:
        return False
    top_scores = [score for score, _ in ranked_results[:top_n]]
    avg_score = sum(top_scores) / len(top_scores)
    debug_info(f"ğŸ“Š ìƒìœ„ {top_n}ê°œ í‰ê·  ìœ ì‚¬ë„: {avg_score:.4f}", pin=True)
    return avg_score >= threshold

def recommend_services(query, top_k=5, exclude_keys=None, use_random=True):
    # âœ… exclude_keysê°€ Noneì´ë©´ ë¹ˆ ì§‘í•©ìœ¼ë¡œ ì´ˆê¸°í™”
    if exclude_keys is None:
        exclude_keys = set()
    
    # 1. ì§ˆì˜ì— ëŒ€í•œ ì„ë² ë”© ìƒì„± ë° ì •ê·œí™”
    query_vec = get_embedding(query)
    query_vec = np.array(query_vec).astype('float32').reshape(1, -1)
    query_vec = normalize(query_vec)

    # âœ… 2. ìœ ì‚¬í•œ ì„œë¹„ìŠ¤ 300ê°œ ê²€ìƒ‰ (ê¸°ì¡´ 100ê°œ â†’ í™•ì¥)
    D, indices = index_cosine.search(query_vec, 300)

    # 3. ìœ ì‚¬ë„ ë†’ì€ ìˆœì„œë¡œ (score, service) ëª©ë¡ ìƒì„±
    ranked = [(score, metadata[idx]) for score, idx in zip(D[0], indices[0])]
    # â›” ìœ ì‚¬ë„ ë‚®ì„ ê²½ìš° GPT í˜¸ì¶œë„ ìƒëµí•  ìˆ˜ ìˆë„ë¡ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    if not is_related_results_enough(ranked):
        debug_info("âš ï¸ [INFO] ì¶”ì²œ ê²°ê³¼ì˜ ì—°ê´€ì„±ì´ ë‚®ì•„ GPT í˜¸ì¶œì„ ìƒëµí•©ë‹ˆë‹¤.", "warning")
        return []
    
    # ğŸ“Œ STEP 1: ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬ëœ ì›ë³¸ ìƒìœ„ 30ê°œ ì¶œë ¥
    debug_info(f"\nğŸ“Œ [STEP 1] ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬ëœ ì›ë³¸ ìƒìœ„ 30ê°œ:")
    for i, (score, s) in enumerate(ranked[:30]):
        debug_info(f"{i+1}. [{score:.4f}] {s['ê¸°ì—…ëª…']} / {s.get('ì„œë¹„ìŠ¤ìœ í˜•')} / {s.get('ì„œë¹„ìŠ¤ëª…')}")
        
    # âœ… 4. ì œì™¸í•  í‚¤ (ê¸°ì—…ID + ì„œë¹„ìŠ¤ìœ í˜• + ì„œë¹„ìŠ¤ëª…) ì •ì˜
    if exclude_keys:
        debug_info(f"\n\nğŸš« [STEP 2] ì œì™¸ ëŒ€ìƒ í‚¤ ìˆ˜: {len(exclude_keys)}")
        for i, key in enumerate(list(exclude_keys)[:10]):
            company_name = company_lookup.get(str(key[0]), "ì•Œ ìˆ˜ ì—†ìŒ")
            debug_info(f" - ì œì™¸ {i+1}: ê¸°ì—…ID={key[0]} / ê¸°ì—…ëª…={company_name} / {key[1]} / {key[2]}")
    else:
        debug_info("\n\nğŸš« [STEP 2] ì œì™¸ ëŒ€ìƒ ì—†ìŒ")

    # 4. ì¤‘ë³µ ì œê±° ë° ì œì™¸ ëŒ€ìƒ í•„í„°ë§
    seen_keys = set()
    filtered = []
    for score, service in ranked:
        key = (service["ê¸°ì—…ID"], service.get("ì„œë¹„ìŠ¤ìœ í˜•"), service.get("ì„œë¹„ìŠ¤ëª…"))
        if key in exclude_keys or key in seen_keys:
            continue
        seen_keys.add(key)
        filtered.append((score, service))

    # 5. ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ì´ë¯¸ ì •ë ¬ë¼ ìˆìœ¼ë‚˜ ì•ˆì „ ì°¨ì›ì—ì„œ ì¬ì •ë ¬)
    filtered.sort(key=lambda x: x[0], reverse=True)
    
    # âœ… ìƒìœ„ 30ê°œê¹Œì§€ ì¶œë ¥ (ë””ë²„ê¹… ë˜ëŠ” ë¡œê·¸ í™•ì¸ìš©)
    debug_info(f"\nâœ… [STEP 3] í•„í„°ë§ í›„ ìƒìœ„ 30ê°œ:")
    for i, (score, s) in enumerate(filtered[:30]):
        debug_info(f"{i+1}. [{score:.4f}] {s['ê¸°ì—…ëª…']} / {s.get('ì„œë¹„ìŠ¤ìœ í˜•')} / {s.get('ì„œë¹„ìŠ¤ëª…')}")

    # 6. ìƒìœ„ 10ê°œ ì¤‘ ëœë¤ ì„ íƒ or top_kê°œ ì„ íƒ
    if use_random:
        top_10 = filtered[:10]
        selected = random.sample(top_10, min(len(top_10), top_k))
        results = [service for _, service in selected]
    else:
        results = [service for _, service in filtered[:top_k]]

    return results

def ask_gpt(messages):
    response = client.chat.completions.create(model="gpt-4o", messages=messages)
    return response.choices[0].message.content

def make_context(results):
    """ì¶”ì²œ ê²°ê³¼ ëª©ë¡ì„ ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë„ë¡ êµ¬ì„± (ê¸°ì—…ì˜ ìƒì„¸ì •ë³´ í¬í•¨)"""
    return "\n".join([
        f"{i+1}. \"{s['ì„œë¹„ìŠ¤ëª…']}\" (ì œê³µê¸°ì—…: \"{s['ê¸°ì—…ëª…']}\", ê¸°ì—…ID: {s['ê¸°ì—…ID']})\n"
        f"- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½', '')}\n"
        f"- ê¸ˆì•¡: {s.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', 'ì •ë³´ ì—†ìŒ')} / ê¸°í•œ: {s.get('ì„œë¹„ìŠ¤ê¸°í•œ', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ë²•ì¸ì—¬ë¶€: {s.get('ê¸°ì—…ì˜ ë²•ì¸ì—¬ë¶€', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ìœ„ì¹˜: {s.get('ê¸°ì—… ìœ„ì¹˜', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- í•µì‹¬ì—­ëŸ‰: {s.get('ê¸°ì—… í•µì‹¬ì—­ëŸ‰', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- 3ê°œë…„ í‰ê·  ë§¤ì¶œ: {s.get('ê¸°ì—… 3ê°œë…„ í‰ê·  ë§¤ì¶œ', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- í•´ë‹¹ë¶„ì•¼ì—…ë ¥: {s.get('ê¸°ì—… í•´ë‹¹ë¶„ì•¼ì—…ë ¥', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ì£¼ìš”ì‚¬ì—…ë‚´ìš©: {s.get('ê¸°ì—… ì£¼ìš”ì‚¬ì—…ë‚´ìš©', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ì¸ë ¥í˜„í™©: {s.get('ê¸°ì—… ì¸ë ¥í˜„í™©', 'ì •ë³´ ì—†ìŒ')}"
        for i, s in enumerate(results)
    ])

def make_summary_context(summary_memory):
    seen = set()
    deduplicated = []
    for result_list in reversed(summary_memory):
        for item in result_list:
            key = (item['ì„œë¹„ìŠ¤ëª…'], item['ê¸°ì—…ëª…'], item.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', 'ì—†ìŒ'))
            if key not in seen:
                seen.add(key)
                deduplicated.insert(0, item)  # ì›ë˜ ìˆœì„œ ìœ ì§€
    return "\n".join([
        f"{i+1}. {s['ì„œë¹„ìŠ¤ëª…']} ({s['ê¸°ì—…ëª…']})\n- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•', 'ì •ë³´ ì—†ìŒ')}\n- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½', '')}"
        for i, s in enumerate(deduplicated)
    ])

def make_prompt(query, context, is_best=False):
    if is_best:
        history = make_summary_context(st.session_state.all_results)
        extra = f"ì§€ê¸ˆê¹Œì§€ ì¶”ì²œí•œ ì„œë¹„ìŠ¤ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n{history}\n\nì´ì „ì— ì¶”ì²œëœ ê¸°ì—…ë„ í¬í•¨í•´ì„œ ì¡°ê±´ì— ê°€ì¥ ë¶€í•©í•˜ëŠ” ìµœê³ ì˜ ì¡°í•©ì„ ì œì‹œí•´ì£¼ì„¸ìš”."
    else:
        extra = ""
        
    return f"""ë‹¹ì‹ ì€ ê´€ê´‘ìˆ˜í˜œê¸°ì—…ì—ê²Œ ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” AI ìƒë‹´ì‚¬ í˜¸ì¢…ì´ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
"{query}"

ê·¸ë¦¬ê³  ê´€ë ¨ëœ ì„œë¹„ìŠ¤ ëª©ë¡ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:
{context}

ğŸ“Œ {extra}
"""

# âœ… UI ì¶œë ¥ ì˜ì—­
st.markdown("""
    <div class="responsive-title">í˜ì‹ ë°”ìš°ì²˜ ì„œë¹„ìŠ¤ íŒŒì¸ë”</div>
    <p class="responsive-subtitle">ğŸ¤– í˜¸ì¢…ì´ì—ê²Œ ê´€ê´‘ê¸°ì—… ì„œë¹„ìŠ¤ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”.</p>
""", unsafe_allow_html=True)

# ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
for msg in st.session_state.chat_messages:
    if msg["role"] == "user":
        st.markdown(f"""
        <div class="user-msg-box">
            <div class="user-msg">
                {msg["content"].replace(chr(10), "<br>")}
                <div class="user-msg-time">{msg['timestamp']}</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chatbot-msg-box">
            <div class="chatbot-msg"> 
                {msg["content"].replace(chr(10), "<br>")}
                <div class="chatbot-msg-time">{msg['timestamp']}</div>
            </div>
        </div>
        """, unsafe_allow_html=True)

if st.session_state.debug_mode and "debug_pinned_message" in st.session_state:
    st.markdown(f"""
        <div style="background-color:#fff3cd; border-left: 6px solid #ffeeba; padding:10px; margin-bottom:10px;">
            "{st.session_state.debug_pinned_message}"
        </div>
    """, unsafe_allow_html=True)

# ì…ë ¥ í¼
with st.form("chat_form", clear_on_submit=True):
    st.markdown("<div class='input-row'>", unsafe_allow_html=True)
    user_input = st.text_area("", height=100, label_visibility="collapsed")
    submitted = st.form_submit_button("ë¬¼ì–´ë³´ê¸°")
    st.markdown("</div>", unsafe_allow_html=True)

# ì‚¬ìš© ì•ˆë‚´ í‘œì‹œ
st.markdown("""
    <div class="user-guide">
        â„¹ï¸ ì‚¬ìš©ë²• ì•ˆë‚´:<br>
        â€¢&nbsp;<b>"ìì„¸íˆ ê¸°ì—…ëª…"</b>ì„ ì…ë ¥í•˜ë©´ í•´ë‹¹ ê¸°ì—…ì˜ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.<br>
        â€¢&nbsp;<b>"ê°•ë ¥ ì¶”ì²œ"</b> ì„ í¬í•¨í•˜ì—¬ ì…ë ¥í•˜ë©´ ì•ì„œ ì œì‹œëœ ì„œë¹„ìŠ¤ë“¤ì„ í¬í•¨í•œ ì „ì²´ ì¶”ì²œì„ ë°›ì•„ë³¼ ìˆ˜ ìˆì–´ìš”.<br>
        â€¢&nbsp;<b>"ì´ˆê¸°í™”"</b>ë¥¼ ì…ë ¥í•˜ë©´ ëŒ€í™” ë‚´ìš©ê³¼ ì¶”ì²œ ê¸°ë¡ì„ ëª¨ë‘ ì§€ìš¸ ìˆ˜ ìˆì–´ìš”.<br>
        â€¢&nbsp;<b>"ë””ë²„ê·¸"</b>ë¥¼ ì…ë ¥í•˜ë©´ ë””ë²„ê·¸ ëª¨ë“œë¡œ ì „í™˜í•  ìˆ˜ ìˆì–´ìš”.<br>
        â€¢&nbsp;ë³µí•©ì ì¸ ì¡°ê±´ë“¤ì„ ì´ìš©í•œ ì§ˆë¬¸ìœ¼ë¡œ í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•´ ë³´ì„¸ìš”.<br>
        ì˜ˆë¥¼ë“¤ì–´ "ìš°ë¦¬ íšŒì‚¬ëŠ” ì™¸êµ­ì¸ì—ê²Œ êµ­ë‚´ ìœ ëª… ê´€ê´‘ì§€ì—­ì„ ì†Œê°œí•˜ê³  ìˆ™ë°•ì„ ì—°ê²°í•´ì£¼ëŠ” ì„œë¹„ìŠ¤ë¥¼ í•˜ê³  ìˆì–´. íšŒì‚¬ í™ˆí˜ì´ì§€ë¥¼ ë””ìì¸ ì¤‘ì‹¬ìœ¼ë¡œ ê°œí¸í•˜ê³  ì‹¶ê³ , ì°¸ ë‹¤êµ­ì–´ëŠ” í•„ìˆ˜ê³ , ìˆ™ë°•ì§€ë¥¼ ì˜ˆì•½í•˜ê³  ê²°ì œí•˜ëŠ” ì‡¼í•‘ëª° ê¸°ëŠ¥ì´ ë°˜ë“œì‹œ í•„ìš”í•´. ë˜í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ìœ¼ë¡œ í™ë³´ë„ ì˜ í•˜ëŠ” ê²ƒë„ í•„ìˆ˜ê³ . ì´ëŸ°ê±¸ ë§Œì¡±ì‹œí‚¬ ìˆ˜ ìˆëŠ” ì¡°í•©ì„ ë§Œë“¤ì–´ì¤˜. ë‹¨, ì˜ˆì‚°ì€ í•©ì³ì„œ 5,000ë§Œì›ê¹Œì§€ì´ê³ , ê¸°ê°„ì€ 3.5ê°œì›”ì•ˆì—ëŠ” ë§ˆì³ì•¼ í•´. ë§ì€ ì†Œí†µì„ ìœ„í•´ ê°€ê¸‰ì  ìˆ˜ë„ê¶Œ ì§€ì—­ì— ìˆëŠ” íšŒì‚¬ì˜€ìœ¼ë©´ ì¢‹ê² ê³ , ë§¤ì¶œë„ 30ì–µ ì´ìƒë˜ë©° ì¸ì›ë„ ë§ì•„ì„œ ì•ˆì •ì ì¸ ì§€ì›ë„ ë°›ì•˜ìœ¼ë©´ í•˜ê³ . ì´ëŸ° íšŒì‚¬ë“¤ë¡œ ì°¾ì•„ë´ì¤˜. ë˜ ì–´ë–»ê²Œ ì´ë“¤ì„ ì¡°í•©í•˜ë©´ ë˜ëŠ”ì§€, ì™œ ì¶”ì²œí–ˆëŠ”ì§€ë„ ìƒì„¸íˆ ì•Œë ¤ì¤˜."
    </div>
""", unsafe_allow_html=True)

# ë©”ì‹œì§€ ì²˜ë¦¬ ë¡œì§
if submitted and user_input.strip():
    # ì‹œê°„ëŒ€ ì„¤ì •
    current_time = get_kst_time()
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.chat_messages.append({"role": "user", "content": user_input, "timestamp": current_time})
    
    # ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€ ëª…ë ¹ ì²˜ë¦¬
    if user_input.strip().lower() == "ë””ë²„ê·¸":
        st.session_state.debug_mode = not st.session_state.debug_mode
        mode_status = "í™œì„±í™”" if st.session_state.debug_mode else "ë¹„í™œì„±í™”"
        st.session_state.chat_messages.append({
            "role": "assistant", 
            "content": f"ğŸ› ï¸ ë””ë²„ê·¸ ëª¨ë“œê°€ {mode_status}ë˜ì—ˆìŠµë‹ˆë‹¤.", 
            "timestamp": current_time
        })
        st.rerun()
    
    # ì´ˆê¸°í™” ëª…ë ¹ ì²˜ë¦¬
    elif user_input.strip().lower() == "ì´ˆê¸°í™”":
        st.session_state.embedding_query_text = None
        st.session_state.excluded_keys.clear()
        st.session_state.all_results.clear()
        st.session_state.conversation_history.clear()
        st.session_state.conversation_history.append({
            "role": "system", 
            "content": "ë‹¹ì‹ ì€ ê´€ê´‘ê¸°ì—… ìƒë‹´ ì „ë¬¸ê°€ í˜¸ì¢…ì´ì…ë‹ˆë‹¤."
        })
        st.session_state.user_query_history = []
        
        # ì´ˆê¸°í™” ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_messages.append({
            "role": "assistant", 
            "content": "ğŸ¤– í˜¸ì¢…ì´ëŠ” ì ì‹œ ë ˆë“œì¬í•˜ê³  ë‹¤ì‹œ ëŒì•„ì™”ìŠµë‹ˆë‹¤.", 
            "timestamp": current_time
        })
        st.rerun()
    
    # 'ìì„¸íˆ' ëª…ë ¹ ì²˜ë¦¬
    elif user_input.strip().startswith("ìì„¸íˆ"):
        keyword = user_input.replace("ìì„¸íˆ", "").strip()
        all_stored_results = list(itertools.chain.from_iterable(st.session_state.all_results))
        
        if not all_stored_results:
            reply = "âš ï¸ ì €ì¥ëœ ì¶”ì²œ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤."
        else:
            keywords = keyword.split()
            matches = [
                s for s in all_stored_results
                if all(any(k in s.get(field, "") for field in ["ê¸°ì—…ëª…", "ì„œë¹„ìŠ¤ëª…"]) for k in keywords)
            ]
            
            if not matches:
                reply = "âš ï¸ í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ê¸°ì—…ëª…ì´ ì—†ìŠµë‹ˆë‹¤."
            elif len(matches) > 1:
                reply = "âš ï¸ ì—¬ëŸ¬ ê°œì˜ í•­ëª©ì´ ì¼ì¹˜í•©ë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.\n" + "\n".join([f"- {s['ê¸°ì—…ëª…']} / {s['ì„œë¹„ìŠ¤ëª…']}" for s in matches])
            else:
                s = matches[0]
                service_link = f"https://www.tourvoucher.or.kr/user/svcManage/svc/BD_selectSvc.do?svcNo={s['ì„œë¹„ìŠ¤ë²ˆí˜¸']}"
                company_link = f"https://www.tourvoucher.or.kr/user/entrprsManage/provdEntrprs/BD_selectProvdEntrprs.do?entrprsId={s['ê¸°ì—…ID']}"
                
                # ìƒì„¸ ì •ë³´ í˜•ì‹í™”
                details = []
                for k, v in s.items():
                    # ê¸°ì—… 3ê°œë…„ í‰ê·  ë§¤ì¶œ: ìˆ«ìë¥¼ ì •ìˆ˜, ì½¤ë§ˆ êµ¬ë¶„ í›„ "ì›" ì¶”ê°€
                    if k == "ê¸°ì—… 3ê°œë…„ í‰ê·  ë§¤ì¶œ":
                        try:
                            num = float(v)
                            v = format(round(num), ",") + "ì›"
                        except Exception:
                            pass
                    # ê¸°ì—… ì¸ë ¥í˜„í™©: ì •ìˆ˜ë¡œ í‘œê¸° í›„ "ëª…" ì¶”ê°€
                    elif k == "ê¸°ì—… ì¸ë ¥í˜„í™©":
                        try:
                            num = float(v)
                            v = f"{int(num)}ëª…"
                        except Exception:
                            pass
                    # ê¸°ì—… í•µì‹¬ì—­ëŸ‰: _x000D_ ì œê±°
                    elif k == "ê¸°ì—… í•µì‹¬ì—­ëŸ‰":
                        try:
                            v = v.replace("_x000D_", "")
                        except Exception:
                            pass
                    details.append(f"â€¢&nbsp;{k}: {v}")
                
                # ë§í¬ ë²„íŠ¼ í˜•ì‹ìœ¼ë¡œ ë³€ê²½
                links = [
                    f'<a href="{service_link}" target="_blank" class="link-button">ğŸ”— ì„œë¹„ìŠ¤ ìƒì„¸ ë³´ê¸°</a>',
                    f'<a href="{company_link}" target="_blank" class="link-button">ğŸ¢ ê¸°ì—… ì •ë³´ ë³´ê¸°</a>'
                ]
                
                reply = "ğŸ“„ ì„œë¹„ìŠ¤ ìƒì„¸ì •ë³´\n" + "\n".join(details) + "\n\n" + "\n".join(links)
        
        # ìƒì„¸ ì •ë³´ ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_messages.append({
            "role": "assistant", 
            "content": reply, 
            "timestamp": current_time
        })
        st.rerun()
    
    # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
    else:
        # ëŒ€í™” ì´ë ¥ì— ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
        st.session_state.conversation_history.append({"role": "user", "content": user_input})
        
        debug_info("\nğŸ¤– í˜¸ì¢…ì´ê°€ ì§ˆë¬¸ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
        # ì§ˆë¬¸ ê´€ë ¨ì„± í™•ì¸
        if not is_relevant_question(user_input):
            reply = "âš ï¸ ì£„ì†¡í•˜ì§€ë§Œ, ì§ˆë¬¸ì˜ ë‚´ìš©ì„ ì¡°ê¸ˆ ë” ê´€ê´‘ê¸°ì—…ì´ë‚˜ ì„œë¹„ìŠ¤ì™€ ê´€ë ¨ëœ ë‚´ìš©ìœ¼ë¡œ ë‹¤ì‹œ í•´ ì£¼ì„¸ìš”."
            st.session_state.chat_messages.append({
                "role": "assistant", 
                "content": reply, 
                "timestamp": current_time
            })
            st.rerun()
        
        # í›„ì† ì§ˆë¬¸ íŒë‹¨
        if st.session_state.user_query_history:
            previous_input = st.session_state.user_query_history[-1]
            if not is_followup_question(previous_input, user_input):
                debug_info("â¡ï¸ [INFO] ë…ë¦½ëœ ì§ˆë¬¸ì…ë‹ˆë‹¤. ê¸°ì¤€ ì„ë² ë”© ê°±ì‹ .")
                st.session_state.embedding_query_text = user_input
            else:
                # í›„ì† ì§ˆë¬¸ì´ë©´ ì´ì „ ì„ë² ë”© ìœ ì§€
                debug_info("â¡ï¸ [INFO] í›„ì† ì§ˆë¬¸ì…ë‹ˆë‹¤. ê¸°ì¤€ ì„ë² ë”© ìœ ì§€.")
        else:
            # ìµœì´ˆ ì§ˆë¬¸ì¸ ê²½ìš°
            debug_info("â¡ï¸ [INFO] ìµœì´ˆ ì§ˆë¬¸ì…ë‹ˆë‹¤. ê¸°ì¤€ ì„ë² ë”© ì„¤ì •.")
            st.session_state.embedding_query_text = user_input
        
        # ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state.user_query_history.append(user_input)
        
        debug_info("ğŸ¤– í˜¸ì¢…ì´ê°€ ê´€ë ¨ ì„œë¹„ìŠ¤ë¥¼ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
        # ì¶”ì²œ ëª¨ë“œ ì„¤ì • ë° ì„œë¹„ìŠ¤ ì¶”ì²œ
        best_mode = is_best_recommendation_query(user_input)
        exclude = None if best_mode else st.session_state.excluded_keys
        last_results = recommend_services(
            st.session_state.embedding_query_text, 
            exclude_keys=exclude, 
            use_random=not best_mode
        )
        
        # ì¶”ì²œ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš°
        if not last_results:
            reply = "âš ï¸ ì¶”ì²œ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ê´€ë ¨ëœ ì—…ì²´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µë“œë¦¬ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤. nê´€ê´‘ê¸°ì—…ì´ë‚˜ ì„œë¹„ìŠ¤ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤!"
            st.session_state.chat_messages.append({
                "role": "assistant", 
                "content": reply, 
                "timestamp": current_time
            })
            st.rerun()
        
        debug_info("ğŸ¤– í˜¸ì¢…ì´ê°€ ì¶”ì²œ ë‚´ìš©ì„ ì •ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
        # ì¶”ì²œ ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        unique_last_results = [
            s for s in last_results
            if (s["ê¸°ì—…ID"], s.get("ì„œë¹„ìŠ¤ìœ í˜•"), s.get("ì„œë¹„ìŠ¤ëª…")) not in st.session_state.excluded_keys
        ]
        context = make_context(unique_last_results)
        gpt_prompt = make_prompt(user_input, context, is_best=best_mode)
        
        # GPTì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬
        st.session_state.conversation_history.append({"role": "user", "content": gpt_prompt})
        
        try:
            gpt_reply = ask_gpt(list(st.session_state.conversation_history))
        except Exception as e:
            gpt_reply = f"âš ï¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”: {str(e)}"
            
        # ì‘ë‹µì„ ì €ì¥í•˜ê³  ëŒ€í™” ì´ë ¥ì— ì¶”ê°€
        st.session_state.conversation_history.append({"role": "assistant", "content": gpt_reply})
        
        # ì´ë²ˆ ì¶”ì²œì—ì„œ ì–¸ê¸‰ëœ ì„œë¹„ìŠ¤ë“¤ ì œì™¸ ëŒ€ìƒìœ¼ë¡œ ë“±ë¡
        mentioned_keys = {
            (s["ê¸°ì—…ID"], s.get("ì„œë¹„ìŠ¤ìœ í˜•"), s.get("ì„œë¹„ìŠ¤ëª…"))
            for s in last_results
            if (
                str(s["ê¸°ì—…ID"]) in gpt_reply and
                s["ì„œë¹„ìŠ¤ëª…"] in gpt_reply
            )
        }
        
        debug_info(f"[â—DEBUG] GPT ì‘ë‹µì—ì„œ ì–¸ê¸‰ëœ í‚¤: {mentioned_keys}")
        for s in last_results:
            ê¸°ì—…ID = s.get('ê¸°ì—…ID')
            ê¸°ì—…ëª… = s.get('ê¸°ì—…ëª…')
            ì„œë¹„ìŠ¤ëª… = s.get('ì„œë¹„ìŠ¤ëª…')
            debug_info(f"ğŸ” ë¹„êµ ì¤‘: {ê¸°ì—…ID} / {ê¸°ì—…ëª…} / {ì„œë¹„ìŠ¤ëª…}")
            debug_info(f"    â†’ ê¸°ì—…ID ë¹„êµ: {ê¸°ì—…ID} in GPT? {'YES' if str(ê¸°ì—…ID) in gpt_reply else 'NO'}")
            debug_info(f"    â†’ ê¸°ì—…ëª… ë¹„êµ: {ê¸°ì—…ëª…} in GPT? {'YES' if ê¸°ì—…ëª… in gpt_reply else 'NO'}")
            debug_info(f"    â†’ ì„œë¹„ìŠ¤ëª… ë¹„êµ: {ì„œë¹„ìŠ¤ëª…} in GPT? {'YES' if ì„œë¹„ìŠ¤ëª… in gpt_reply else 'NO'}")
        debug_info(f"\nğŸ” excluded_keys í‚¤ ìˆ˜: {len(st.session_state.excluded_keys)}")
        
        # ì œì™¸ ëŒ€ìƒ ì—…ë°ì´íŠ¸
        st.session_state.excluded_keys.update(mentioned_keys)
        
        # ì¶”ì²œ ê²°ê³¼ ì €ì¥
        st.session_state.last_results = last_results
        st.session_state.all_results.append(last_results)
        
        # ì±—ë´‡ ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_messages.append({
            "role": "assistant", 
            "content": gpt_reply, 
            "timestamp": current_time
        })
        
        st.rerun()