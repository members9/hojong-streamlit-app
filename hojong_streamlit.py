# hojong_streamlit.py (ë°˜ì‘í˜• ê°œì„  ë²„ì „)
import streamlit as st
import faiss
import pickle
import numpy as np
import random
import itertools
from collections import deque
from openai import OpenAI

# âœ… ìŠ¤íƒ€ì¼ ë° ë°˜ì‘í˜• CSS ì¶”ê°€
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');

        html, body, [class*="css"] {
            background-color: #000000 !important;
            color: #FFFFFF !important;
            font-family: 'Noto Sans KR', sans-serif !important;
        }

        .message-box {
            background-color: #F2F2FF;
            color: #000000;
            padding: 12px;
            border-radius: 8px;
            margin-bottom: 20px;
            word-break: break-word;
        }

        .chat-row {
            display: flex;
            flex-direction: column;
            gap: 12px;
        }

        .input-row {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            align-items: flex-end;
            margin-top: 12px;
        }

        .input-row textarea {
            flex-grow: 1;
            min-width: 250px;
            background-color: #1c1c1c;
            color: #fff;
            border-radius: 6px;
            padding: 10px;
            border: 1px solid #444;
        }

        .stButton button {
            background-color: #444;
            color: white;
            padding: 8px 16px;
            border-radius: 6px;
            border: none;
        }

        @media screen and (max-width: 768px) {
            .input-row {
                flex-direction: column;
                align-items: stretch;
            }
        }
    </style>
""", unsafe_allow_html=True)

# OpenAI client ì´ˆê¸°í™”
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# FAISS ë¡œë”©
index = faiss.read_index("service_index.faiss")
with open("service_metadata.pkl", "rb") as f:
    metadata = pickle.load(f)

# ìƒíƒœ ì´ˆê¸°í™”
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ê´€ê´‘ê¸°ì—… ìƒë‹´ ì „ë¬¸ê°€ í˜¸ì¢…ì´ì…ë‹ˆë‹¤."}
    ]
if "all_results" not in st.session_state:
    st.session_state.all_results = deque(maxlen=5)
if "excluded_company_ids" not in st.session_state:
    st.session_state.excluded_company_ids = set()
if "last_results" not in st.session_state:
    st.session_state.last_results = []
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []

# ë²¡í„° ì •ê·œí™” í•¨ìˆ˜
def normalize(vecs):
    norms = np.linalg.norm(vecs, axis=1, keepdims=True)
    return vecs / norms

# cosine index ì¤€ë¹„
xb = index.reconstruct_n(0, index.ntotal)
xb = normalize(xb)
d = xb.shape[1]
index_cosine = faiss.IndexFlatIP(d)
index_cosine.add(xb)
SIMILARITY_THRESHOLD = 0.30

# ì„ë² ë”© í•¨ìˆ˜
def get_embedding(text, model="text-embedding-3-small"):
    response = client.embeddings.create(input=[text], model=model)
    return response.data[0].embedding

def ask_gpt(messages):
    response = client.chat.completions.create(model="gpt-4o", messages=messages)
    return response.choices[0].message.content

def is_best_recommendation_query(query):
    keywords = ["ì¶”ì²œ", "ê°•ì¶”", "ì†Œê°œí•´", "ì•ˆë‚´í•´", "ì œì‹œí•´"]
    return any(k in query for k in keywords)

def recommend_services(query, top_k=5, exclude_company_ids=None):
    query_vec = get_embedding(query)
    query_vec = np.array(query_vec).astype('float32').reshape(1, -1)
    query_vec = normalize(query_vec)
    D, indices = index_cosine.search(query_vec, 100)

    candidate_services = {}
    for score, idx in zip(D[0], indices[0]):
        service = metadata[idx]
        cid = service["ê¸°ì—…ID"]
        if exclude_company_ids and cid in exclude_company_ids:
            continue
        key = (cid, service.get("ì„œë¹„ìŠ¤ìœ í˜•"))
        candidate_services.setdefault(key, []).append((score, service))

    best_services = [random.choice(v) for v in candidate_services.values()]
    best_services.sort(key=lambda x: x[0], reverse=True)
    return [s for _, s in best_services[:top_k]]

def is_relevant_question(query, threshold=SIMILARITY_THRESHOLD):
    query_vec = get_embedding(query)
    query_vec = np.array(query_vec).astype('float32').reshape(1, -1)
    query_vec = normalize(query_vec)
    D, _ = index_cosine.search(query_vec, 1)
    return D[0][0] >= threshold

def make_context(results):
    return "\n".join([
        f"{i+1}. {s['ì„œë¹„ìŠ¤ëª…']} ({s['ê¸°ì—…ëª…']})\n"
        f"- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½', '')}\n"
        f"- ê¸ˆì•¡: {s.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', 'ì •ë³´ ì—†ìŒ')} / ê¸°í•œ: {s.get('ì„œë¹„ìŠ¤ê¸°í•œ', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ë²•ì¸ì—¬ë¶€: {s.get('ê¸°ì—…ì˜ ë²•ì¸ì—¬ë¶€', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ìœ„ì¹˜: {s.get('ê¸°ì—… ìœ„ì¹˜', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- í•µì‹¬ì—­ëŸ‰: {s.get('ê¸°ì—… í•µì‹¬ì—­ëŸ‰', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- 3ê°œë…„ í‰ê·  ë§¤ì¶œ: {s.get('ê¸°ì—… 3ê°œë…„ í‰ê·  ë§¤ì¶œ', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- í•´ë‹¹ë¶„ì•¼ì—…ë ¥: {s.get('ê¸°ì—… í•´ë‹¹ë¶„ì•¼ì—…ë ¥', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ì£¼ìš”ì‚¬ì—…ë‚´ìš©: {s.get('ê¸°ì—… ì£¼ìš”ì‚¬ì—…ë‚´ìš©', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ì¸ë ¥í˜„í™©: {s.get('ê¸°ì—… ì¸ë ¥í˜„í™©', 'ì •ë³´ ì—†ìŒ')}"
        for i, s in enumerate(results)
    ])

def make_summary_context(summary_memory):
    seen = set()
    deduplicated = []
    for result_list in reversed(summary_memory):
        for item in result_list:
            key = (item['ì„œë¹„ìŠ¤ëª…'], item['ê¸°ì—…ëª…'], item.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', 'ì—†ìŒ'))
            if key not in seen:
                seen.add(key)
                deduplicated.insert(0, item)
    return "\n".join([
        f"{i+1}. {s['ì„œë¹„ìŠ¤ëª…']} ({s['ê¸°ì—…ëª…']})\n- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•', 'ì •ë³´ ì—†ìŒ')}\n- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½', '')}"
        for i, s in enumerate(deduplicated)
    ])

def make_prompt(query, context, is_best=False):
    style_instruction = (
        "- ë‹µë³€ì€ ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”. ê° ì¶”ì²œ í•­ëª©ì€ ë²ˆí˜¸ë¥¼ ë¶™ì´ê³ , ê¸°ì—…ëª…, ì„œë¹„ìŠ¤ëª…, ì„œë¹„ìŠ¤ ìœ í˜•, ê¸ˆì•¡, ê¸°í•œ, ë²•ì¸ì—¬ë¶€, ìœ„ì¹˜, í•µì‹¬ì—­ëŸ‰, 3ê°œë…„ í‰ê·  ë§¤ì¶œ, í•´ë‹¹ë¶„ì•¼ì—…ë ¥, ì£¼ìš”ì‚¬ì—…ë‚´ìš©, ì¸ë ¥í˜„í™©ì„ ìƒì„¸í•˜ê²Œ ê¸°ìˆ í•´ ì£¼ì„¸ìš”.\n"
        "- ì„œë¹„ìŠ¤ëª…ê³¼ ê¸°ì—…ëª…ì€ ë°˜ë“œì‹œ ë”°ì˜´í‘œë¡œ ë¬¶ê³ , ëª©ë¡ì€ ëŒ€ì‹œ(-)ë¡œ ë‚˜ì—´í•´ ì£¼ì„¸ìš”."
    ) if "ì¶”ì²œ" in query else "- ë‹µë³€ì€ ì„œìˆ ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ê¸°ì—… ì •ë³´ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”."

    extra = f"\nì§€ê¸ˆê¹Œì§€ ì¶”ì²œí•œ ì„œë¹„ìŠ¤ ëª©ë¡:\n{make_summary_context(st.session_state.all_results)}" if is_best else ""

    return f"""
ë‹¹ì‹ ì€ ê´€ê´‘ìˆ˜í˜œê¸°ì—…ì—ê²Œ ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” AI ìƒë‹´ì‚¬ í˜¸ì¢…ì´ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
"{query}"

ê´€ë ¨ ì„œë¹„ìŠ¤ ëª©ë¡:
{context}

ğŸ“Œ ì¡°ê±´:
{style_instruction}
{extra}
- ë™ì¼í•œ ê¸°ì—…ì˜ ì„œë¹„ìŠ¤ê°€ ì—¬ëŸ¬ ê°œì¼ ê²½ìš°, í•˜ë‚˜ë§Œ ì„ íƒí•´ ì£¼ì„¸ìš”.
- íŠ¹ìˆ˜ë¬¸ìëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , ë¶€ë“œëŸ¬ìš´ ìƒë‹´ì‚¬ ë§íˆ¬ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
"""

# ----------------------- UI ----------------------- #
st.markdown("""
    <h1 style='text-align: center;'>í˜ì‹ ì´ìš©ê¶Œ ì„œë¹„ìŠ¤ íŒŒì¸ë”</h1>
    <p style='text-align: center; font-size:14px;'>ğŸ¤– í˜¸ì¢…ì´ì—ê²Œ ê´€ê´‘ê¸°ì—… ì„œë¹„ìŠ¤ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”.</p>
""", unsafe_allow_html=True)

for msg in st.session_state.chat_messages:
    role_class = "message-box"
    st.markdown(f"<div class='{role_class}'>{msg['content'].replace(chr(10), '<br>')}</div>", unsafe_allow_html=True)

with st.form("chat_form", clear_on_submit=True):
    st.markdown("<div class='input-row'>", unsafe_allow_html=True)
    user_input = st.text_area("", height=100, label_visibility="collapsed", key="input_box")
    submitted = st.form_submit_button("ë¬¼ì–´ë³´ê¸°")
    st.markdown("</div>", unsafe_allow_html=True)
    
st.markdown("""
    <div style='font-size: 14px; margin-top: 4px; color: #CCCCCC; text-align: left;'>
        â„¹ï¸ ì‚¬ìš©ë²• ì•ˆë‚´:<br>
        â€¢ <b>"ìì„¸íˆ ê¸°ì—…ëª…"</b>ì„ ì…ë ¥í•˜ë©´ í•´ë‹¹ ê¸°ì—…ì˜ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.<br>
        â€¢ <b>"ì¶”ì²œ"</b> ìœ¼ë¡œ ì§ˆë¬¸í•˜ë©´ ì¢…í•© ì¶”ì²œì„ ë°›ì•„ë³¼ ìˆ˜ ìˆì–´ìš”.<br>
        â€¢ ìµœê·¼ ì¶”ì²œë°›ì€ ê¸°ì—…ì€ ìë™ìœ¼ë¡œ ì¤‘ë³µ ì œì™¸ë¼ìš”.<br>
        â€¢ ë³µí•©ì ì¸ ì¡°ê±´ë“¤ì„ ì´ìš©í•œ ì§ˆë¬¸ìœ¼ë¡œ í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•´ ë³´ì„¸ìš”.<br>
        &nbsp;&nbsp;ì˜ˆë¥¼ë“¤ì–´ "ìš°ë¦¬ íšŒì‚¬ëŠ” êµ­ë‚´ ìœ ëª… ê´€ê´‘ì§€ì—­ì„ ì†Œê°œí•˜ê³  ìˆ™ë°•ì„ ì—°ê²°í•´ì£¼ëŠ” ì„œë¹„ìŠ¤ë¥¼ í•˜ê³  ìˆì–´. íšŒì‚¬ í™ˆí˜ì´ì§€ë¥¼ ë””ìì¸ ì¤‘ì‹¬ìœ¼ë¡œ ê°œí¸í•˜ê³  ì‹¶ê³ , ìˆ™ë°•ì§€ë¥¼ ì˜ˆì•½í•˜ê³  ê²°ì œí•˜ëŠ” ì‡¼í•‘ëª° ê¸°ëŠ¥ì´ ë°˜ë“œì‹œ í•„ìš”í•´. ì´ 2ê°€ì§€ë¥¼ ë§Œì¡±ì‹œí‚¬ ìˆ˜ ìˆëŠ” ì¡°í•©ì„ ë§Œë“¤ì–´ì¤˜. ë‹¨, ì˜ˆì‚°ì€ í•©ì³ì„œ 5,000ë§Œì›ê¹Œì§€ì´ê³ , ê¸°ê°„ì€ 3.5ê°œì›”ì•ˆì—ëŠ” ë§ˆì³ì•¼ í•´. ë§ì€ ì†Œí†µì„ ìœ„í•´ ê°€ê¸‰ì  ìˆ˜ë„ê¶Œ ì§€ì—­ì— ìˆëŠ” íšŒì‚¬ì˜€ìœ¼ë©´ ì¢‹ê² ê³ , ë§¤ì¶œë„ 30ì–µ ì´ìƒë˜ë©° ì¸ì›ë„ ë§ì•„ì„œ ì•ˆì •ì ì¸ ì§€ì›ë„ ë°›ì•˜ìœ¼ë©´ í•˜ê³ . ì´ëŸ° íšŒì‚¬ë¥¼ ì¢€ ì¶”ì²œ í•´ì¤˜."

    </div>
""", unsafe_allow_html=True)    

if submitted and user_input.strip():
    st.session_state.conversation_history.append({"role": "user", "content": user_input})
    st.session_state.chat_messages.append({"role": "user", "content": user_input})

    if user_input.startswith("ìì„¸íˆ"):
        keyword = user_input.replace("ìì„¸íˆ", "").strip()
        all_results = list(itertools.chain.from_iterable(st.session_state.all_results))
        matches = [s for s in all_results if keyword in s["ê¸°ì—…ëª…"]]
        if not matches:
            reply = "â— í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ê¸°ì—…ëª…ì´ ì—†ìŠµë‹ˆë‹¤."
        elif len(matches) > 1:
            reply = "â— ì—¬ëŸ¬ ê°œì˜ ê¸°ì—…ëª…ì´ ì¼ì¹˜í•©ë‹ˆë‹¤:<br>" + "<br>".join(f"- {s['ê¸°ì—…ëª…']}" for s in matches)
        else:
            s = matches[0]
            service_link = f"https://www.tourvoucher.or.kr/user/svcManage/svc/BD_selectSvc.do?svcNo={s['ì„œë¹„ìŠ¤ë²ˆí˜¸']}"
            company_link = f"https://www.tourvoucher.or.kr/user/entrprsManage/provdEntrprs/BD_selectProvdEntrprs.do?entrprsId={s['ê¸°ì—…ID']}"
            details = []
            for k, v in s.items():
                if k == "ê¸°ì—… 3ê°œë…„ í‰ê·  ë§¤ì¶œ":
                    try: v = format(int(v), ",") + "ì›"
                    except: pass
                elif k == "ê¸°ì—… ì¸ë ¥í˜„í™©":
                    try: v = f"{int(float(v))}ëª…"
                    except: pass
                elif k == "ê¸°ì—… í•µì‹¬ì—­ëŸ‰":
                    v = v.replace("_x000D_", ", ")
                if k == "ê¸°ì—…ëª…":
                    details.append(f"â€¢ <b>{k}: {v}</b>")
                else:
                    details.append(f"â€¢ {k}: {v}")
            reply = "<br>".join(details) + f"<br>ğŸ”— ì„œë¹„ìŠ¤ ë§í¬: <a href='{service_link}' target='_blank'>{service_link}</a><br>ğŸ¢ ê¸°ì—… ë§í¬: <a href='{company_link}' target='_blank'>{company_link}</a>"
        st.session_state.chat_messages.append({"role": "assistant", "content": reply})

    else:
        if not is_relevant_question(user_input):
            msg = "â— ê´€ê´‘ê¸°ì—…ì´ë‚˜ ì„œë¹„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”."
            st.session_state.chat_messages.append({"role": "assistant", "content": msg})
        else:
            best_mode = is_best_recommendation_query(user_input)
            exclude = None if best_mode else st.session_state.excluded_company_ids
            results = recommend_services(user_input, exclude_company_ids=exclude)

            if not best_mode:
                for s in results:
                    st.session_state.excluded_company_ids.add(s["ê¸°ì—…ID"])

            st.session_state.last_results = results
            st.session_state.all_results.append(results)
            context = make_context(results)
            prompt = make_prompt(user_input, context, is_best=best_mode)

            st.session_state.conversation_history.append({"role": "user", "content": prompt})
            gpt_reply = ask_gpt(st.session_state.conversation_history)
            st.session_state.conversation_history.append({"role": "assistant", "content": gpt_reply})
            st.session_state.chat_messages.append({"role": "assistant", "content": gpt_reply})

    st.rerun()
