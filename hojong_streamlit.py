# service_recommender.py
import streamlit as st
import openai
import faiss
import pickle
import numpy as np
import random  # ëœë¤ ì„ íƒì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
import itertools  # ì—¬ëŸ¬ ë¦¬ìŠ¤íŠ¸ë¥¼ í•©ì¹˜ê¸° ìœ„í•´ ì‚¬ìš©
from collections import deque
from openai import OpenAI

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¡œë“œ (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œ)
index = faiss.read_index("service_index.faiss")
with open("service_metadata.pkl", "rb") as f:
    metadata = pickle.load(f)

def normalize(vecs):
    norms = np.linalg.norm(vecs, axis=1, keepdims=True)
    return vecs / norms

# ì €ì¥ëœ ì„ë² ë”© ë²¡í„° ì¬êµ¬ì„± ë° ì •ê·œí™”
xb = index.reconstruct_n(0, index.ntotal)
xb = normalize(xb)
d = xb.shape[1]
index_cosine = faiss.IndexFlatIP(d)
index_cosine.add(xb)

SIMILARITY_THRESHOLD = 0.30

# ----------------------- í•¨ìˆ˜ ì •ì˜ ----------------------- #
def get_embedding(text, model="text-embedding-3-small"):
    response = openai.Embedding.create(input=[text], model=model)
    return response['data'][0]['embedding']

def is_best_recommendation_query(query):
    keywords = ["ê°€ì¥", "ìµœê³ ", "ì œì¼", "1ë“±", "1ìœ„", "ì§„ì§œ ì¶”ì²œ", "ê°•ë ¥ ì¶”ì²œ", "ì •ë§ ì¶”ì²œ", "ìµœì„ "]
    return any(k in query for k in keywords)

def recommend_services(query, top_k=5, exclude_company_ids=None):
    query_vec = get_embedding(query)
    query_vec = np.array(query_vec).astype('float32').reshape(1, -1)
    query_vec = normalize(query_vec)
    D, indices = index_cosine.search(query_vec, 100)

    candidate_services = {}
    for score, idx in zip(D[0], indices[0]):
        service = metadata[idx]
        cid = service["ê¸°ì—…ID"]
        if exclude_company_ids and cid in exclude_company_ids:
            continue
        service_type = service.get("ì„œë¹„ìŠ¤ìœ í˜•", None)
        key = (cid, service_type)
        candidate_services.setdefault(key, []).append((score, service))
        
    best_services = []
    for candidate_list in candidate_services.values():
        chosen_score, chosen_service = random.choice(candidate_list)
        best_services.append((chosen_score, chosen_service))
    best_services.sort(key=lambda x: x[0], reverse=True)
    results = [service for score, service in best_services[:top_k]]
    return results

def is_relevant_question(query, threshold=SIMILARITY_THRESHOLD):
    query_vec = get_embedding(query)
    query_vec = np.array(query_vec).astype('float32').reshape(1, -1)
    query_vec = normalize(query_vec)
    D, _ = index_cosine.search(query_vec, 1)
    max_similarity = D[0][0]
    return max_similarity >= threshold

def ask_gpt(messages):
    response = openai.ChatCompletion.create(model="gpt-4o", messages=messages)
    return response['choices'][0]['message']['content']

def make_context(results):
    """ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ê¸°ì—…ì˜ ìƒì„¸ì •ë³´ í¬í•¨"""
    return "\n".join([
        f"{i+1}. {s['ì„œë¹„ìŠ¤ëª…']} ({s['ê¸°ì—…ëª…']})\n"
        f"- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½', '')}\n"
        f"- ê¸ˆì•¡: {s.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', 'ì •ë³´ ì—†ìŒ')} / ê¸°í•œ: {s.get('ì„œë¹„ìŠ¤ê¸°í•œ', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ë²•ì¸ì—¬ë¶€: {s.get('ê¸°ì—…ì˜ ë²•ì¸ì—¬ë¶€', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ìœ„ì¹˜: {s.get('ê¸°ì—… ìœ„ì¹˜', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- í•µì‹¬ì—­ëŸ‰: {s.get('ê¸°ì—… í•µì‹¬ì—­ëŸ‰', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- 3ê°œë…„ í‰ê·  ë§¤ì¶œ: {s.get('ê¸°ì—… 3ê°œë…„ í‰ê·  ë§¤ì¶œ', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- í•´ë‹¹ë¶„ì•¼ì—…ë ¥: {s.get('ê¸°ì—… í•´ë‹¹ë¶„ì•¼ì—…ë ¥', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ì£¼ìš”ì‚¬ì—…ë‚´ìš©: {s.get('ê¸°ì—… ì£¼ìš”ì‚¬ì—…ë‚´ìš©', 'ì •ë³´ ì—†ìŒ')}\n"
        f"- ì¸ë ¥í˜„í™©: {s.get('ê¸°ì—… ì¸ë ¥í˜„í™©', 'ì •ë³´ ì—†ìŒ')}"
        for i, s in enumerate(results)
    ])

def make_summary_context(summary_memory):
    seen = set()
    deduplicated = []
    for result_list in reversed(summary_memory):
        for item in result_list:
            key = (item['ì„œë¹„ìŠ¤ëª…'], item['ê¸°ì—…ëª…'], item.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', 'ì—†ìŒ'))
            if key not in seen:
                seen.add(key)
                deduplicated.insert(0, item)
    return "\n".join([
        f"{i+1}. {s['ì„œë¹„ìŠ¤ëª…']} ({s['ê¸°ì—…ëª…']})\n- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•', 'ì •ë³´ ì—†ìŒ')}\n- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½', '')}"
        for i, s in enumerate(deduplicated)
    ])

def make_prompt(query, context, is_best=False):
    if "ì¶”ì²œ" in query:
        style_instruction = (
            "- ë‹µë³€ì€ ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”. ê° ì¶”ì²œ í•­ëª©ì€ ë²ˆí˜¸ë¥¼ ë¶™ì´ê³ , "
            "ê¸°ì—…ëª…, ì„œë¹„ìŠ¤ëª…, ì„œë¹„ìŠ¤ ìœ í˜•, ê¸ˆì•¡, ê¸°í•œ, ë²•ì¸ì—¬ë¶€, ìœ„ì¹˜, í•µì‹¬ì—­ëŸ‰, 3ê°œë…„ í‰ê·  ë§¤ì¶œ, "
            "í•´ë‹¹ë¶„ì•¼ì—…ë ¥, ì£¼ìš”ì‚¬ì—…ë‚´ìš©, ì¸ë ¥í˜„í™©ì„ ìƒì„¸í•˜ê²Œ ê¸°ìˆ í•´ ì£¼ì„¸ìš”.\n"
            "- ë‹µë³€ ì‹œ ë°˜ë“œì‹œ ì„œë¹„ìŠ¤ëª…ê³¼ ê¸°ì—…ëª…ì€ ë”°ì˜´í‘œë¡œ ë¬¶ì–´ì£¼ì‹œê³ , ëª©ë¡ í‘œê¸° ì‹œì—ëŠ” ëŒ€ì‹œ(-)ë¡œë§Œ ë‚˜ì—´í•´ ì£¼ì„¸ìš”."
        )
    else:
        style_instruction = (
            "- ë‹µë³€ì€ ì„œìˆ ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ê¸°ì—… ì •ë³´(ë§¤ì¶œ, ì¸ì›, ë²•ì¸ì—¬ë¶€ ë“±)ë„ í¬í•¨í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
        )
    
    if is_best:
        history = make_summary_context(st.session_state.all_results)
        extra = f"ì§€ê¸ˆê¹Œì§€ ì¶”ì²œí•œ ì„œë¹„ìŠ¤ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n{history}\n\nì´ì „ì— ì¶”ì²œëœ ê¸°ì—…ë„ í¬í•¨í•´ì„œ ì¡°ê±´ì— ê°€ì¥ ë¶€í•©í•˜ëŠ” ìµœê³ ì˜ ì¡°í•©ì„ ì œì‹œí•´ì£¼ì„¸ìš”."
    else:
        extra = ""
        
    return f"""ë‹¹ì‹ ì€ ê´€ê´‘ìˆ˜í˜œê¸°ì—…ì—ê²Œ ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” AI ìƒë‹´ì‚¬ í˜¸ì¢…ì´ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
"{query}"

ê·¸ë¦¬ê³  ê´€ë ¨ëœ ì„œë¹„ìŠ¤ ëª©ë¡ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:
{context}

ğŸ“Œ {extra}

ğŸ“Œ ë‹¤ìŒ ì¡°ê±´ì„ ì§€ì¼œì„œ ë‹µë³€í•´ì£¼ì„¸ìš”:
{style_instruction}
- ë§Œì•½ ë™ì¼í•œ ì„œë¹„ìŠ¤ìœ í˜•ê³¼ ë™ì¼í•œ íšŒì‚¬ì˜ ì„œë¹„ìŠ¤ëª…ì´ ë³µìˆ˜ê°œì¼ ê²½ìš°ì—ëŠ” í•´ë‹¹ íšŒì‚¬ì˜ ë‹¨ 1ê°œì˜ ì„œë¹„ìŠ¤ë§Œ ì„ íƒí•´ ì£¼ì„¸ìš”.
- ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ì(**, ## ë“±)ì€ ì‚¬ìš©í•˜ì§€ ë§ì•„ ì£¼ì„¸ìš”.
- ë¶€ë“œëŸ¬ìš´ ìƒë‹´ì‚¬ ë§íˆ¬ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
"""

# ----------------------- Streamlit ìƒíƒœ ì´ˆê¸°í™” ----------------------- #
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ê´€ê´‘ê¸°ì—… ìƒë‹´ ì „ë¬¸ê°€ í˜¸ì¢…ì´ì…ë‹ˆë‹¤."}
    ]
if "all_results" not in st.session_state:
    st.session_state.all_results = deque(maxlen=5)
if "excluded_company_ids" not in st.session_state:
    st.session_state.excluded_company_ids = set()
if "last_results" not in st.session_state:
    st.session_state.last_results = []
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []  # ì‚¬ìš©ìì™€ AIì˜ ì±„íŒ…ì„ ì €ì¥

# ----------------------- í™”ë©´ êµ¬ì„± ----------------------- #
st.markdown("<h1 style='text-align: center;'>ê´€ê´‘ê³µì‚¬ ì„œë¹„ìŠ¤ ê°€ì´ë“œ AI</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; font-size:14px;'>ğŸ¤– í˜¸ì¢…ì´ì—ê²Œ ì–´ë–¤ ì„œë¹„ìŠ¤ë‚˜ ê¸°ì—…ì„ ì°¾ìœ¼ì‹œëŠ”ì§€ ë¬¼ì–´ë³´ì„¸ìš”.</p>", unsafe_allow_html=True)

chat_container = st.container()
with chat_container:
    # ì±„íŒ…ì°½ í‘œì‹œ (ìŠ¤í¬ë¡¤ë°” ìˆëŠ” ì˜ì—­)
    for msg in st.session_state.chat_messages:
        if msg["role"] == "user":
            st.markdown(f"<p style='background-color:#DCF8C6; padding:8px; border-radius:5px; text-align:right;'>{msg['content']}</p>", unsafe_allow_html=True)
        else:
            st.markdown(f"<p style='background-color:#FFFFFF; padding:8px; border-radius:5px; text-align:left;'>{msg['content']}</p>", unsafe_allow_html=True)

# í•˜ë‹¨ ë©”ì‹œì§€ ì•ˆë‚´
st.markdown("<p style='text-align:center; font-size:12px;'>""ìì„¸íˆ ê¸°ì—…ëª…"" ì„ ì…ë ¥í•˜ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>", unsafe_allow_html=True)

# ----------------------- ì±„íŒ… ì…ë ¥ í¼ ----------------------- #
with st.form(key="chat_form", clear_on_submit=True):
    user_input = st.text_area("ë©”ì‹œì§€ ì…ë ¥", height=80)  # 3ì¤„ ì •ë„ì˜ ë†’ì´
    submitted = st.form_submit_button("ë¬¼ì–´ë³´ê¸°")

if submitted and user_input.strip() != "":
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ì´ë ¥ ë° ì±„íŒ… ë©”ì‹œì§€ì— ì¶”ê°€
    st.session_state.conversation_history.append({"role": "user", "content": user_input})
    st.session_state.chat_messages.append({"role": "user", "content": user_input})
    
    # 'ìì„¸íˆ' ëª…ë ¹ ì²˜ë¦¬: ì „ì²´ ì €ì¥ ë‚´ì—­(all_results)ì—ì„œ ê²€ìƒ‰
    if user_input.startswith("ìì„¸íˆ"):
        all_stored_results = list(itertools.chain.from_iterable(st.session_state.all_results))
        if not all_stored_results:
            detail_msg = "ì €ì¥ëœ ì¶”ì²œ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤."
            st.session_state.chat_messages.append({"role": "assistant", "content": detail_msg})
        else:
            keyword = user_input.replace("ìì„¸íˆ", "").strip()
            matches = [s for s in all_stored_results if keyword in s["ê¸°ì—…ëª…"]]
            if not matches:
                detail_msg = "í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ê¸°ì—…ëª…ì´ ì—†ìŠµë‹ˆë‹¤."
                st.session_state.chat_messages.append({"role": "assistant", "content": detail_msg})
            elif len(matches) > 1:
                multiple_msg = "ì—¬ëŸ¬ ê°œì˜ ê¸°ì—…ëª…ì´ ì¼ì¹˜í•©ë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.\n"
                for s in matches:
                    multiple_msg += f"- {s['ê¸°ì—…ëª…']}\n"
                st.session_state.chat_messages.append({"role": "assistant", "content": multiple_msg})
            else:
                s = matches[0]
                service_link = f"https://www.tourvoucher.or.kr/user/svcManage/svc/BD_selectSvc.do?svcNo={s['ì„œë¹„ìŠ¤ë²ˆí˜¸']}"
                company_link = f"https://www.tourvoucher.or.kr/user/entrprsManage/provdEntrprs/BD_selectProvdEntrprs.do?entrprsId={s['ê¸°ì—…ID']}"
                detail_lines = []
                for k, v in s.items():
                    if k == "ê¸°ì—… 3ê°œë…„ í‰ê·  ë§¤ì¶œ":
                        try:
                            num = float(v)
                            v = format(int(num), ",") + "ì›"
                        except Exception:
                            pass
                    elif k == "ê¸°ì—… ì¸ë ¥í˜„í™©":
                        try:
                            num = float(v)
                            v = f"{int(num)}ëª…"
                        except Exception:
                            pass
                    elif k == "ê¸°ì—… í•µì‹¬ì—­ëŸ‰":
                        try:
                            v = v.replace("_x000D_", "")
                        except Exception:
                            pass
                    detail_lines.append(f"{k}: {v}")
                detail_msg = "\n".join(detail_lines)
                detail_msg += f"\nğŸ”— ì„œë¹„ìŠ¤ ë§í¬: {service_link}\nğŸ¢ ê¸°ì—… ë§í¬: {company_link}"
                st.session_state.chat_messages.append({"role": "assistant", "content": detail_msg})
    else:
        # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
        if not is_relevant_question(user_input):
            msg = "ì£„ì†¡í•˜ì§€ë§Œ, ì§ˆë¬¸ì˜ ë‚´ìš©ì„ ì¡°ê¸ˆ ë” ê´€ê´‘ê¸°ì—…ì´ë‚˜ ì„œë¹„ìŠ¤ì™€ ê´€ë ¨ëœ ë‚´ìš©ìœ¼ë¡œ ë‹¤ì‹œ í•´ ì£¼ì„¸ìš”."
            st.session_state.chat_messages.append({"role": "assistant", "content": msg})
        else:
            best_mode = is_best_recommendation_query(user_input)
            exclude = None if best_mode else st.session_state.excluded_company_ids
            last_results = recommend_services(user_input, exclude_company_ids=exclude)
            # ì œì™¸ ëŒ€ìƒ ì—…ë°ì´íŠ¸
            if not best_mode:
                for s in last_results:
                    st.session_state.excluded_company_ids.add(s['ê¸°ì—…ID'])
            st.session_state.last_results = last_results
            st.session_state.all_results.append(last_results)
            context = make_context(last_results)
            prompt_text = make_prompt(user_input, context, is_best=best_mode)
            st.session_state.conversation_history.append({"role": "user", "content": prompt_text})
            
            # AIì—ê²Œ ì „ì²´ ëŒ€í™” ì´ë ¥ì„ ì „ë‹¬í•˜ì—¬ ì‘ë‹µ ìƒì„±
            gpt_reply = ask_gpt(st.session_state.conversation_history)
            try:
                gpt_reply = gpt_reply.replace("\n\n", "\n")
            except Exception:
                pass
            st.session_state.conversation_history.append({"role": "assistant", "content": gpt_reply})
            st.session_state.chat_messages.append({"role": "assistant", "content": gpt_reply})
    
    # ê°•ì œë¡œ í˜ì´ì§€ ì¬ì‹¤í–‰í•˜ì—¬ ìµœì‹  ëŒ€í™”ê°€ ë°˜ì˜ë˜ë„ë¡ í•¨.
    st.experimental_rerun()
