import streamlit as st
from streamlit_chat import message
import openai
import faiss
import pickle
import numpy as np
from collections import deque
import os
from openai import OpenAI

# OpenAI API ì„¤ì •
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# FAISS ë° ë©”íƒ€ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
index = faiss.read_index("service_index.faiss")
with open("service_metadata.pkl", "rb") as f:
    metadata = pickle.load(f)

xb = index.reconstruct_n(0, index.ntotal)
xb = xb / np.linalg.norm(xb, axis=1, keepdims=True)
d = xb.shape[1]
index_cosine = faiss.IndexFlatIP(d)
index_cosine.add(xb)

# ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "last_results" not in st.session_state:
    st.session_state.last_results = []
if "excluded_company_ids" not in st.session_state:
    st.session_state.excluded_company_ids = set()
if "all_results" not in st.session_state:
    st.session_state.all_results = deque(maxlen=3)

SIMILARITY_THRESHOLD = 0.30

# í•¨ìˆ˜ ì •ì˜
def get_embedding(text, model="text-embedding-3-small"):
    response = client.embeddings.create(input=[text], model=model)
    return np.array(response.data[0].embedding).astype('float32')

def is_best_recommendation_query(query):
    keywords = ["ê°€ì¥", "ìµœê³ ", "ì œì¼", "1ë“±", "1ìœ„", "ì§„ì§œ ì¶”ì²œ", "ê°•ë ¥ ì¶”ì²œ", "ì •ë§ ì¶”ì²œ", "ìµœì„ ì˜ ë°©ì•ˆ"]
    return any(k in query for k in keywords)

def recommend_services(query, top_k=5, exclude_company_ids=None):
    query_vec = get_embedding(query).reshape(1, -1)
    query_vec = query_vec / np.linalg.norm(query_vec)
    D, indices = index_cosine.search(query_vec, 100)
    results, seen_companies = [], set(exclude_company_ids) if exclude_company_ids else set()

    for i in indices[0]:
        service = metadata[i]
        if service["ê¸°ì—…ID"] not in seen_companies:
            results.append(service)
            seen_companies.add(service["ê¸°ì—…ID"])
        if len(results) == top_k:
            break
    return results

def is_relevant_question(query):
    vec = get_embedding(query).reshape(1, -1)
    vec = vec / np.linalg.norm(vec)
    D, _ = index_cosine.search(vec, 1)
    return D[0][0] >= SIMILARITY_THRESHOLD

def ask_gpt(messages):
    response = client.chat.completions.create(model="gpt-4o", messages=messages)
    return response.choices[0].message.content

def make_context(results):
    return "\n".join([
        f"{i+1}. {s['ì„œë¹„ìŠ¤ëª…']} ({s['ê¸°ì—…ëª…']})\n- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•', 'ì •ë³´ ì—†ìŒ')}\n- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½', '')}\n- ê¸ˆì•¡: {s.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', 'ì •ë³´ ì—†ìŒ')} / ê¸°í•œ: {s.get('ì„œë¹„ìŠ¤ê¸°í•œ', 'ì •ë³´ ì—†ìŒ')}"
        for i, s in enumerate(results)
    ])

def make_summary_context(memory):
    seen, deduped = set(), []
    for group in reversed(memory):
        for s in group:
            key = (s['ì„œë¹„ìŠ¤ëª…'], s['ê¸°ì—…ëª…'], s.get('ì„œë¹„ìŠ¤ê¸ˆì•¡', ''))
            if key not in seen:
                seen.add(key)
                deduped.insert(0, s)
    return "\n".join([
        f"{i+1}. {s['ì„œë¹„ìŠ¤ëª…']} ({s['ê¸°ì—…ëª…']})\n- ìœ í˜•: {s.get('ì„œë¹„ìŠ¤ìœ í˜•', 'ì •ë³´ ì—†ìŒ')}\n- ìš”ì•½: {s.get('ì„œë¹„ìŠ¤ìš”ì•½', '')}"
        for i, s in enumerate(deduped)
    ])

def make_prompt(query, context, is_best=False):
    if is_best:
        history = make_summary_context(st.session_state.all_results)
        extra = f"ì§€ê¸ˆê¹Œì§€ ì¶”ì²œí•œ ì„œë¹„ìŠ¤ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n{history}\nì´ì „ì— ì¶”ì²œëœ ê¸°ì—…ë„ í¬í•¨í•´ì„œ ì¡°ê±´ì— ê°€ì¥ ë¶€í•©í•˜ëŠ” ìµœê³ ì˜ ì¡°í•©ì„ ì œì‹œí•´ì£¼ì„¸ìš”."
    else:
        extra = "ì´ì „ ì¶”ì²œëœ ê¸°ì—…ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ì¶”ì²œì„ ìµœëŒ€ 5ê°œê¹Œì§€ ë¶€íƒë“œë¦½ë‹ˆë‹¤."

    return f"""ë‹¹ì‹ ì€ ê´€ê´‘ìˆ˜í˜œê¸°ì—…ì—ê²Œ ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” AI ìƒë‹´ì‚¬ í˜¸ì¢…ì´ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
"{query}"

ê·¸ë¦¬ê³  ê´€ë ¨ëœ ì„œë¹„ìŠ¤ ëª©ë¡ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:
{context}

ğŸ“Œ {extra}

ğŸ“Œ ë‹¤ìŒ ì¡°ê±´ì„ ì§€ì¼œì„œ ì¶”ì²œí•´ì£¼ì„¸ìš”:
1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì† ì¡°ê±´ì´ë‚˜ ëª©ì ì„ ìš°ì„  íŒŒì•…í•˜ì„¸ìš”.
2. ë™ì¼í•œ íšŒì‚¬ ë˜ëŠ” ì„œë¹„ìŠ¤ëŠ” ì¤‘ë³µí•˜ì§€ ë§ê³ , ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ì¤‘ì‹¬ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”.
3. ì¡°ê±´ì„ ì¼ë¶€ ì™„í™”í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ëª©ì ì„ ê°€ì§„ ëŒ€ì²´ ì„œë¹„ìŠ¤ë„ ì¶”ì²œ ê°€ëŠ¥í•©ë‹ˆë‹¤.
4. ê° ì¶”ì²œì€ ë²ˆí˜¸ë¥¼ ë¶™ì´ê³ , ê¸°ì—…ëª…, ì„œë¹„ìŠ¤ëª…, ì„œë¹„ìŠ¤ ìœ í˜•, ê¸ˆì•¡, ê¸°í•œ, ì¥ì , ë‹¨ì , ì¶”ì²œì´ìœ ë¥¼ ë¶„ì„ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
5. 4ë²ˆì˜ ë‹µë³€ ìƒì„± ì‹œ ë°˜ë“œì‹œ ì„œë¹„ìŠ¤ëª…ê³¼ ê¸°ì—…ëª…ì€ ë”°ì˜´í‘œ(\")ë¡œ ë¬¶ì–´ì£¼ê³ , ëª©ë¡ í‘œê¸°ì‹œì—ëŠ” ëŒ€ì‹œ(-) ë¡œë§Œ ë‚˜ì—´í•´ì£¼ì„¸ìš”.
6. ë‹µë³€ ì‹œ ë¶ˆí•„ìš”í•˜ê²Œ íŠ¹ìˆ˜ë¬¸ì(*, # ë“±)ë¡œ ë¨¸ë¦¿ë§ì„ ì‚¬ìš© í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”.
7. ë¶€ë“œëŸ¬ìš´ ìƒë‹´ì‚¬ ë§íˆ¬ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”."""

# Streamlit ë ˆì´ì•„ì›ƒ
st.markdown("""
<h1 style='text-align: center;'>ê´€ê´‘ê¸°ì—… ì„œë¹„ìŠ¤ ì¶”ì²œ AI</h1>
<p style='text-align: center;'>ì„œë¹„ìŠ¤ ì¶”ì²œì„ ì›í•˜ì‹œëŠ” ì§ˆë¬¸ì„ í•˜ì‹œë©´, í˜¸ì¢…ì´ê°€ ë„ì™€ë“œë¦½ë‹ˆë‹¤!</p>
""", unsafe_allow_html=True)

with st.container():
    # ì±„íŒ… ì¶œë ¥ ì˜ì—­
    chat_box = st.container()
    with chat_box:
        for i, (q, a) in enumerate(st.session_state.chat_history):
            message(q, is_user=True, key=f"user_{i}")
            message(a, key=f"ai_{i}")

    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.text_area("", placeholder="ì˜ˆ: ìš°ë¦¬ í™ˆí˜ì´ì§€ì— ì˜ˆì•½ ì‹œìŠ¤í…œê³¼ ë””ìì¸ì„ ê°œì„ í•˜ê³  ì‹¶ì–´ìš”", height=80, key="user_text")
    send = st.button("í˜¸ì¢…ì´ì—ê²Œ ì§ˆë¬¸í•˜ê¸°")

# í•˜ë‹¨ ìƒíƒœ ì¶œë ¥
status_placeholder = st.empty()

if send and user_input.strip():
    status_placeholder.info("ğŸ¤– ì§ˆë¬¸ ë¶„ì„ ì¤‘...")
    if not is_relevant_question(user_input):
        status_placeholder.warning("â— ê´€ê´‘ê¸°ì—… ì„œë¹„ìŠ¤ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.")
    else:
        best_mode = is_best_recommendation_query(user_input)
        exclude = None if best_mode else st.session_state.excluded_company_ids

        status_placeholder.info("ğŸ” ê´€ë ¨ ì„œë¹„ìŠ¤ íƒìƒ‰ ì¤‘...")
        results = recommend_services(user_input, exclude_company_ids=exclude)
        st.session_state.last_results = results

        if not best_mode:
            for s in results:
                st.session_state.excluded_company_ids.add(s['ê¸°ì—…ID'])

        st.session_state.all_results.append(results)
        context = make_context(results)
        prompt = make_prompt(user_input, context, is_best=best_mode)

        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê´€ê´‘ê¸°ì—… ìƒë‹´ ì „ë¬¸ê°€ í˜¸ì¢…ì´ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt},
        ]

        status_placeholder.info("âœï¸ ì¶”ì²œ ì •ë¦¬ ì¤‘...")
        reply = ask_gpt(messages)

        # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
        st.session_state.chat_history.append((user_input, reply))
        st.experimental_rerun()
